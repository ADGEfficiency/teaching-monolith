{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from common import load_forest_fires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "## Resources\n",
    "\n",
    "sklearn docs - [Feature selection](https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection)\n",
    "\n",
    "Why giving your algorithm ALL THE FEATURES does not always work - Thomas Huijskens - [youtube](https://youtu.be/JsArBz46_3s)\n",
    "\n",
    "[Automated Feature Engineering and Selection in Python](https://www.youtube.com/watch?v=4-4pKPv9lJ4)\n",
    "\n",
    "## Why select features\n",
    "\n",
    "- colinearity\n",
    "- reduces noise (+ overfitting)\n",
    "- more interpretable\n",
    "- train models quicker\n",
    "- train models better\n",
    "\n",
    "Adding features is an exponential cost!\n",
    "- curse of dimensionality\n",
    "- model needs to understand the new feature in the context of every other feature\n",
    "\n",
    "What makes a good feature selection algorithm\n",
    "- remove low information features\n",
    "- reduce overlap between features\n",
    "\n",
    "We don't want univariate methods\n",
    "- two features that are useless alone useful together\n",
    "- lack of correlation != no complimentarity\n",
    "\n",
    "## Three categories of feature selection\n",
    "\n",
    "1. Wrappers\n",
    "- assess performance by performance of a model\n",
    "- new model for each set of features -> expensive\n",
    "\n",
    "2. Filter\n",
    "- only consider statistics of the data (correlation, mutual infomation, variance thresholding)\n",
    "- ignore interaction with learning algorithm\n",
    "\n",
    "3. Embedded\n",
    "- combinations of wrapping & filters\n",
    "- feature selection as part of the model construction process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_forest_fires()\n",
    "\n",
    "x = ds.loc[:, ['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain']]\n",
    "y = ds.loc[:, 'area']\n",
    "\n",
    "ds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance selection\n",
    "\n",
    "Based only on the feature\n",
    "- no information about the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(threshold=(0.8))\n",
    "sel.fit_transform(x)\n",
    "\n",
    "x.columns[sel.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate feature selection\n",
    "\n",
    "Selecting features in isolation, based on statistical relationship to the target\n",
    "\n",
    "[sklearn docs](https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 6\n",
    "selector = SelectKBest(mutual_info_regression, k=k)\n",
    "features = selector.fit_transform(x, y)\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns[selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score, f in zip(selector.scores_, x.columns):\n",
    "    print(score, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SelectFromModel\n",
    "\n",
    "Requires an interpretable model\n",
    "- coefficients in linear regression\n",
    "- feature importances\n",
    "\n",
    "Select features based on a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = ExtraTreesRegressor(n_estimators=50)\n",
    "mdl.fit(x, y)\n",
    "model = SelectFromModel(mdl, prefit=True, threshold='mean')\n",
    "x_new = model.transform(x)\n",
    "x.columns[model.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability selection\n",
    "\n",
    "Wraps around base learner\n",
    "- base learner must have a regularization hyperparameter\n",
    "- runs learner on many bootstrapped samples for a range of regularization\n",
    "\n",
    "Algorithm\n",
    "\n",
    "```python\n",
    "for regularization_parameter \n",
    "    for bootstraps\n",
    "        bootstrap a dataset\n",
    "        fit a model on the dataset\n",
    "        select features \n",
    "        \n",
    "    save average stability score across all bootstraps\n",
    "    \n",
    "select features based on average across all regularization params\n",
    "```\n",
    "\n",
    "## Practical\n",
    "\n",
    "Implement stability selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 100}\n",
    "depths = np.array(np.arange(1, 20, 2).tolist() + [None,])\n",
    "\n",
    "#from answers import stability_selection_rf_regressor\n",
    "features = stability_selection_rf_regressor(x, y, params, depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
