{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from answers import expectation, ucb, run_ucb_expt\n",
    "from common import generate_bandit_dataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Armed Bandits\n",
    "\n",
    "## Resources\n",
    "\n",
    "- Chapter 3 of [Practical Statistics for Data Scientists](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/)\n",
    "- Chapter 2 of [Sutton & Barto - Reinforcement Learning: An Introduction](http://incompleteideas.net/book/RLbook2018.pdf).\n",
    "\n",
    "## When is classical hypothesis testing not enough?\n",
    "\n",
    "In classical hypothesis testing we\n",
    "- run an experiment, collecting a dataset of A & B\n",
    "- perform a hypothesis test on observed effects (differences between A and B)\n",
    "\n",
    "There are a few problems with this\n",
    "- we only compare two options (one of which is usually a default)\n",
    "- we might lose money by showing customers a suboptimal option \n",
    "- the hypothesis test only shows us if an observed effect is unlikely, not if the effect is large\n",
    "- in a real business, there is no 'experiment over' date\n",
    "- the real world is non-stationary - the results we collect might be from a distribution that is changing\n",
    "\n",
    "We want an experiment where we can **take advantage of the results as we learn** - not have to wait until the experiment results can be used\n",
    "\n",
    "In a business context we are not concerned with statistical significance - we are (often) concerned with optimizing money as quickly as possible\n",
    "\n",
    "## The mulit-armed bandit\n",
    "\n",
    "Bandits allow\n",
    "- testing multiple options at once\n",
    "- reach conclusions faster\n",
    "\n",
    "The term bandit comes from slot machines \n",
    "- one armed bandits for their ability to extract money from gamblers\n",
    "\n",
    "The goal of a multi armed bandit problem is to win as much money as possible\n",
    "- this is the same as figuring out which arm is best as quick as possible\n",
    "\n",
    "Bandits are a simplification of the full reinforcement learing problem\n",
    "\n",
    "## Exploration versus exploitation\n",
    "\n",
    "Favourite restaurant or somewhere new?\n",
    "- if you know all the restaurants well, trust your judgement\n",
    "- if you don't, just randomly pick\n",
    "\n",
    "## Reinforcement learning context\n",
    "\n",
    "Bandits share in common with reinforcement learning\n",
    "- exploration versus exploitation problem (which arm to pull)\n",
    "- potentially non-stationary\n",
    "\n",
    "Is supervised learning we use data learn a function to use for prediction on unseen data\n",
    "- in a bandit problem we could predict the expected value of each arm\n",
    "- this is **prediction** / evaluation\n",
    "\n",
    "Use data (the results we get from pulling an arm) to select an action\n",
    "- this is **control**\n",
    "\n",
    "We can define the value of an action (pulling a specific arm) as an expectation\n",
    "- the expected reward of an action\n",
    "\n",
    "$q_{*}(a) = \\mathbb{E}[r(a)]$\n",
    "\n",
    "Reinforcement learning has a **convenient goal** - maximizing expected reward\n",
    "- if we did know the true expectation of each action, maximization is an argmax\n",
    "\n",
    "The bandit problem is one step short of the full reinforcement learning problem\n",
    "- the bandit is a single state, no transitions of state happen\n",
    "\n",
    "## Example\n",
    "\n",
    "You have the following results from comparing different landing pages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': [3.2858017902970236, 12.083189226273435, 3.9805822512457185],\n",
       " '1': [10.066502149238072, 14.221031572038052, 11.779338983317063],\n",
       " '2': [14.440936232072064, 9.349207821890246, 12.353062777950633],\n",
       " '3': [16.827372626012608, 11.007322332882627, 18.048536401533077],\n",
       " '4': [13.258063218575218, 15.913702094060907, 13.248883537552269],\n",
       " '5': [36.448590412267905, 20.41029297998412, 11.434180481066196],\n",
       " '6': [30.427040651410564, 11.061341529404531, 24.611030928981165],\n",
       " '7': [20.416916500497667, 21.80896927064079, 25.170805905115923],\n",
       " '8': [30.231640940958822, 27.628679657818296, 26.31128370690849],\n",
       " '9': [27.855160894438153, 23.584256410806795, 26.3362438353519],\n",
       " '10': [26.531582014728716, 41.4280109032164, 34.425155596137984],\n",
       " '11': [30.917403331206522, 33.569744317196054, 32.66852781169808],\n",
       " '12': [33.56542652963262, 36.79725195636628, 37.84892143316182],\n",
       " '13': [44.90149751322413, 30.580034143325676, 34.867218222210106],\n",
       " '14': [42.24423086159517, 47.63272933501728, 35.46607439281778],\n",
       " '15': [40.02881384431714, 32.341759041132356, 31.591388333770862],\n",
       " '16': [49.58462664224798, 53.53298123746897, 43.16128599866096],\n",
       " '17': [51.08530958042037, 47.6978964642039, 42.38505280177773],\n",
       " '18': [50.10376561316281, 57.295977406395366, 47.67575036318674],\n",
       " '19': [61.54540811874875, 30.66906398692133, 56.064767406669915]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params, results = generate_bandit_dataset(arms=20, samples=3)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical \n",
    "\n",
    "Write a function to take an expectation over the results\n",
    "- one number for each arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 6.449857755938726,\n",
       " '1': 12.022290901531063,\n",
       " '2': 12.047735610637647,\n",
       " '3': 15.294410453476104,\n",
       " '4': 14.14021628339613,\n",
       " '5': 22.764354624439406,\n",
       " '6': 22.03313770326542,\n",
       " '7': 22.46556389208479,\n",
       " '8': 28.057201435228535,\n",
       " '9': 25.925220380198947,\n",
       " '10': 34.12824950469437,\n",
       " '11': 32.38522515336689,\n",
       " '12': 36.070533306386906,\n",
       " '13': 36.782916626253304,\n",
       " '14': 41.78101152981008,\n",
       " '15': 34.65398707307345,\n",
       " '16': 48.75963129279264,\n",
       " '17': 47.056086282134004,\n",
       " '18': 51.691831127581644,\n",
       " '19': 49.426413170779995}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer\n",
    "expectation(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One approach would be to conclude that one of the arms is optimal and send all our users there\n",
    "- this is a **greedy** solution to the exploration & exploitation dilemma\n",
    "\n",
    "## Practical\n",
    "\n",
    "Take a greedy action based on the results\n",
    "- take the argmax across expected reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with a greedy strategy is that we might have noise in our samples that\n",
    "- our expectation has variance\n",
    "\n",
    "## Question to class\n",
    "\n",
    "Is the expectation above biased?\n",
    "\n",
    "## epsilon-greedy\n",
    "\n",
    "Another solution would be to favour the option that appears optimal, while still sampling from the options that appear sub-optimal.\n",
    "\n",
    "A simple algorithm to tackle the exploration-exploitation dilemma is known as **epsilon-greedy** - it is the method used for exploration in DeepMind's 2013 DQN.\n",
    "\n",
    "The algorithm has a single parameter $\\epsilon$, which controls how greedy we are.  \n",
    "\n",
    "- $\\epsilon$ = 1 -> standard A/B test\n",
    "- $\\epsilon$ = 0 -> greedy\n",
    "\n",
    "In reinforcement learning $\\epsilon$ is often decayed from 1 to a 0.05 over an agents lifetime.  Proper selection of $\\epsilon$ depends on\n",
    "- how accurate your greedy estimate is\n",
    "- how non-stationary the process is\n",
    "\n",
    "The basic algorithm is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_performance(results):\n",
    "    d = []\n",
    "    for arm, data in results.items():\n",
    "        d.extend(data)\n",
    "    return np.mean(d)\n",
    "\n",
    "results = {\n",
    "    arm: list(np.random.normal(*stats))\n",
    "    for arm, stats in params.items()\n",
    "}\n",
    "\n",
    "eps = 0.1\n",
    "choices = list(params.keys())\n",
    "\n",
    "steps = 5000\n",
    "values = np.zeros((steps, len(choices)))\n",
    "actions = np.empty((steps)).astype(str)\n",
    "eps_performance = np.zeros(steps)\n",
    "\n",
    "for step in range(steps):\n",
    "    prob = np.random.rand()\n",
    "    if prob < eps:\n",
    "        strat = 'random'\n",
    "        action = np.random.choice(choices)\n",
    "\n",
    "    else:\n",
    "        strat = 'greedy'\n",
    "        expectations = expectation(results)\n",
    "        values[step, :] = list(expectations.values())\n",
    "        action = max(expectations, key=expectations.get)\n",
    "        \n",
    "    actions[step] = action\n",
    "    \n",
    "    p = params[action]\n",
    "    results[action].append(float(np.random.normal(p.loc, p.scale, 1)))\n",
    "    eps_performance[step] = get_performance(results)\n",
    "    \n",
    "plt.plot(eps_performance, label='eps {}'.format(eps))\n",
    "_ = plt.legend()\n",
    "\n",
    "#TODO put min & max lines of arms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Upper Confidence Bound (UCB)\n",
    "\n",
    "2.7 in [Sutton & Barto - Reinforcement Learning: An Introduction](http://incompleteideas.net/book/RLbook2018.pdf)\n",
    "\n",
    "Select an action based on it's historical mean + an exploration bonus\n",
    "\n",
    "$a = \\underset{x}{\\text{argmax}} \\left[ q(a) + c \\cdot \\sqrt{\\frac{\\ln t}{N(a)}} \\right] $\n",
    "\n",
    "$t$ = timestep\n",
    "\n",
    "$N(a)$ = number of times action $a$ taken\n",
    "\n",
    "## Practical\n",
    "\n",
    "Implement a function that performs a UCB update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 10.273913287407838,\n",
       " '1': 12.843363350429518,\n",
       " '2': 14.666006063279706,\n",
       " '3': 16.075008269848635,\n",
       " '4': 16.968774062158456,\n",
       " '5': 22.538054493081816,\n",
       " '6': 20.561717876277847,\n",
       " '7': 25.24475159004208,\n",
       " '8': 27.279680394725855,\n",
       " '9': 28.81436602729014,\n",
       " '10': 32.73304087366401,\n",
       " '11': 33.22259473363141,\n",
       " '12': 35.417693517876735,\n",
       " '13': 34.81674328439648,\n",
       " '14': 37.490595854209786,\n",
       " '15': 44.39062675309795,\n",
       " '16': 43.6884226472542,\n",
       " '17': 46.057264867766676,\n",
       " '18': 48.62244598390119,\n",
       " '19': 50.19934554779485}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 0.5\n",
    "# answer\n",
    "ucb(results, step, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical\n",
    "\n",
    "Implement a UCB experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7a845e85d439>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# answer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mucb_performance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_ucb_expt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps_performance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mucb_performance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ucb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DSR/teaching-monolith/statistics/answers.py\u001b[0m in \u001b[0;36mrun_ucb_expt\u001b[0;34m(c)\u001b[0m\n\u001b[1;32m     78\u001b[0m     results = {\n\u001b[1;32m     79\u001b[0m         \u001b[0marm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0marm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     }\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "# answer\n",
    "ucb_performance = run_ucb_expt(5)\n",
    "\n",
    "plt.plot(eps_performance, label='eps') \n",
    "plt.plot(ucb_performance, label='ucb')\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
