{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `multiprocessing`\n",
    "\n",
    "Parallel computation on a single machine in Python\n",
    "- one of my most important tools\n",
    "- Python standard library\n",
    "\n",
    "\n",
    "## Python standard library parallel computation ecosystem\n",
    "\n",
    "[Multiprocessing Vs. Threading In Python - Sid Panjwani](https://timber.io/blog/multiprocessing-vs-multithreading-in-python-what-you-need-to-know/)\n",
    "\n",
    "`threading` - uses threads (same memory space)\n",
    "- helps with network issues\n",
    "\n",
    "`multiprocessing` - uses processes (different memory space)\n",
    "- help with compute issues\n",
    "\n",
    "How does this relate to CPU cores\n",
    "- CPU cores are fixed (usually 4-16 in laptops - depends on your physical hardware)\n",
    "- more cores = true parallelism (opposed to the very fast task switching done by the OS\n",
    "- your computer can have many threads and many processes (depends on the OS)\n",
    "- the OS will schedule these threads/processes to available cores\n",
    "- a single thread consumes an entire core\n",
    "\n",
    "[Multithreading and multicore differences](https://stackoverflow.com/questions/11835046/multithreading-and-multicore-differences)\n",
    "\n",
    "*But my CPU core has two threads*\n",
    "- this is a different use of the term (the hardware thread)\n",
    "- CPU having threads allows a core to run thread in parallel, as if there were multiple cores\n",
    "- known as hyperthreading\n",
    "\n",
    "\n",
    "## Why do we need `multiprocessing`?\n",
    "\n",
    "Python has a Global Interpreter Lock (GIL) that prevents parallelizing computation across multiple cores\n",
    "- Python is not thread safe\n",
    "- requires a lock when accessing an object (a form of memory management)\n",
    "\n",
    "\n",
    "## What can be hard in multiprocessing?\n",
    "\n",
    "Sharing things between processes\n",
    "- solution = don't use it in this way\n",
    "- make every process independent\n",
    "- a functional style = no interaction (because interaction = side effects!)\n",
    "\n",
    "\n",
    "## `multiprocessing` 101\n",
    "\n",
    "We map functions to data\n",
    "- but in parallel!\n",
    "\n",
    "First let's do a simple `map` in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def subtract(x, sleep=0.01):\n",
    "    time.sleep(sleep)\n",
    "    return x*x\n",
    "\n",
    "data = np.random.uniform(0, 100, size=100).tolist()\n",
    "st = time.time()\n",
    "result = list(map(subtract, data))\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's parallelize this using `multiprocessing`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "num_process = 8\n",
    "st = time.time()\n",
    "with Pool(num_process) as pool:\n",
    "    out = pool.map(subtract, data)\n",
    "    \n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common use case is to have arguments for the function being mapped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "st = time.time()\n",
    "with Pool(num_process) as p:\n",
    "    rewards = p.map(partial(subtract, sleep=0.0), data)\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when we remove our sleep, the non-mulitprocessing `map` is faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "result = list(map(partial(subtract, sleep=0.0), data))\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed computation has overhead (fixed + variable) \n",
    "- make sure your function runs long enough to justify it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolutionary methods with `multiprocessing`\n",
    "\n",
    "*At least let me have a little fun!*\n",
    "\n",
    "Context on evolutionary algorithms from the Four Competences (on whiteboard)\n",
    "- [more context here](https://towardsdatascience.com/daniel-c-dennetts-four-competences-779648bdbabc?source=friends_link&sk=15fe38a0971a25c0ddb028aec05109a4)\n",
    "- **neuroevolution** = using evolutionary methods to find the parameters (or even architecture) of a neural network\n",
    "\n",
    "Computational evolutionary methods\n",
    "- general, black box optimization\n",
    "- gradient free \n",
    "- work in challenging cost functions (non-linear, discontinuous etc)\n",
    "- can be parallelized\n",
    "\n",
    "Sample inefficient\n",
    "- because they learn from a weak learning signal (fitness / total episode reward)\n",
    "- don't learn from state / reward transitions that occur during an episode\n",
    "\n",
    "## Generate, test & select\n",
    "\n",
    "Evolutionary improvement occurs through a **generate, test & select loop**\n",
    "- substrate independent\n",
    "\n",
    "Our algorithm will:\n",
    "- generate a population of parameters (neural network weights and biases)\n",
    "- test these parameters in the `mountaincar` environment\n",
    "- select the best performing set of parameters to use in the next generate step\n",
    "\n",
    "Let's first setup the code for the forward pass of a neural net.  We aren't going to do any backprop, so we can do it all in `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gym -q\n",
    "\n",
    "import gym\n",
    "from evolution import initialize_parameters, episode, forward\n",
    "\n",
    "#  need this to get the size of the nn input & outpun\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "i_size = env.observation_space.shape[0]\n",
    "h_size = 10\n",
    "o_size = env.action_space.shape[0]\n",
    "params = initialize_parameters(i_size, h_size, o_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We end up with a dictionary of parameters with random weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the function forward to select an action using these parameters & a randomly sampled observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = forward(env.observation_space.sample(), params)\n",
    "action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below the machinery for saving and loading parameters is given - this is so you can run `python render_mountaincar.py` when you agent is learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evolution import save_params, load_params\n",
    "\n",
    "params = initialize_parameters(i_size, h_size, o_size)\n",
    "save_params(params, 1)\n",
    "params = load_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should be able to run (in a shell - will break your notebook kernel):\n",
    "\n",
    "```bash\n",
    "$ python render.py --agent_id 1\n",
    "```\n",
    "\n",
    "![](assets/car.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The components of a simple evolutionary algorithm\n",
    "\n",
    "Above we have outlined the code we need to do the test step of generate/test/select.  Now we will outline the code for the generate & select steps.\n",
    "\n",
    "For the first generation, the loop is to **generate** a population with random weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_size = 32\n",
    "pop = [initialize_parameters(i_size, h_size, o_size) for _ in range(pop_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test** the population in the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list(map(episode, pop))\n",
    "print(np.mean(results))\n",
    "assert len(results) == pop_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select** the best performing parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = pop[np.argmax(results)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now on the second generation.  \n",
    "\n",
    "We still sample a new generation randomly, but now we use the results of the first generation to create the distribution to sample from.\n",
    "\n",
    "Below we create a new generation, using the best performing member to estimate the mean + an identity covariance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_params(best):\n",
    "    p = {}\n",
    "    for k, v in best.items():\n",
    "        flat = v.flatten()\n",
    "        new = np.random.multivariate_normal(flat, np.eye(flat.shape[0]), size=1)\n",
    "        p[k] = new.reshape(v.shape)\n",
    "    return p\n",
    "\n",
    "pop = [sample_params(best) for _ in range(pop_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list(map(episode, pop))\n",
    "print(np.mean(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical\n",
    "\n",
    "Take the components above and put them together:\n",
    "- implement an evolutionary method using `map` (single core)\n",
    "- implement an evolutionary method using `pool.map` (multi-core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
