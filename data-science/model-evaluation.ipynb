{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation\n",
    "\n",
    "[How (and why) to create a good validation set](https://www.fast.ai/2017/11/13/validation-sets/)\n",
    "\n",
    "[Understanding and diagnosing your machine-learning models - GaÃ«l Varoquaux](https://www.youtube.com/watch?v=kbj3llSbaVA)\n",
    "\n",
    "Be the algorithm\n",
    "- solve manually\n",
    "- if you can't, can you expect a machine too?\n",
    "\n",
    "Look at the samples you get wrong\n",
    "- best, worst, uncertain (50% probability in classification)\n",
    "\n",
    "## Train / test / validation / holdout\n",
    "\n",
    "### Train\n",
    "\n",
    "- used to find statistics & parameters of a model\n",
    "\n",
    "### Validation\n",
    "\n",
    "- aka test\n",
    "- used to find hyperparameters & select a model\n",
    "- should both be representative of new/future data\n",
    "\n",
    "### Holdout\n",
    "\n",
    "- aka test\n",
    "- how well did my final model do\n",
    "- should be representative of new/future data\n",
    "- use a test set to evaluate the performance of the model selected using the previous steps\n",
    "\n",
    "## Metrics\n",
    "\n",
    "Align with a business objective / product\n",
    "- possible to have a good ML model with a bad product\n",
    "\n",
    "Most are **aggregates**\n",
    "- lose/hide infomation\n",
    "\n",
    "### Classification metrics\n",
    "\n",
    "BLUE, cross entropy\n",
    "- key question = can I take a gradient?\n",
    "\n",
    "Zero one loss \n",
    "- hard to optimize\n",
    "\n",
    "**Always look at class cardinality & imbalance**\n",
    "- more classes = harder problem\n",
    "- imbalance = easier (can predict most common class & do well)\n",
    "\n",
    "### Accuracy\n",
    "- correct / all predictions\n",
    "- not useful with strong imbalance\n",
    "- LOC 2390 of building ml powered\n",
    "\n",
    "### Confusion matrix\n",
    "\n",
    "|  | 0 | 1 |\n",
    "| --- | --- | --- |\n",
    "| 0| tn | fn |\n",
    "| 1| fp | tp |\n",
    "\n",
    "\n",
    "### Precision\n",
    "- tp / (tp + fp)\n",
    "- how many positive predictions were correct\n",
    "- false detection\n",
    "- fraction of all predictions of class 1 that are correct\n",
    "- minimize false positives\n",
    "\n",
    "### Recall\n",
    "- tp / (tp + fn)\n",
    "- how many positives did I detect out of all the positives\n",
    "- misses\n",
    "- how many of the true class 1 did I predict\n",
    "\n",
    "**Note that only one term changes in the definitions of precision & recall!**\n",
    "- whether you are dealing with fp (precision) or fn (recall)\n",
    "\n",
    "Always tradeoff between precision & recall\n",
    "\n",
    "Predicitive maintenance\n",
    "- false positives = ok, false negatives = not ok\n",
    "\n",
    "## True / false positive rates\n",
    "\n",
    "Measuring p with r = nonsense\n",
    "- can maximize one at the cost of the other\n",
    "\n",
    "F1\n",
    "\n",
    "Area under ROC\n",
    "- 1 = perfect, 0.5 = random\n",
    "- use for classifiers that can modify a threshold\n",
    "- summarizes tradeoffs in varying the threshold\n",
    "- what does under the line of ROC mean?\n",
    "\n",
    "Threshold tuning\n",
    "\n",
    "Average precision\n",
    "- averaged over all recalls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an imbalanced dataset, by selecting only the sevens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = load_digits()\n",
    "\n",
    "y = data.target\n",
    "x = data.data / 255\n",
    "\n",
    "noise = np.random.random(size=x.size).reshape(x.shape)\n",
    "x += noise * 0.5\n",
    "y = (y == 3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "model.fit(x, y)\n",
    "\n",
    "probs = model.decision_function(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y, probs)\n",
    "\n",
    "roc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "print(roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression metrics\n",
    "\n",
    "MAE\n",
    "\n",
    "MSE\n",
    "\n",
    "RMSE\n",
    "\n",
    "MAPE\n",
    "\n",
    "MASE\n",
    "\n",
    "Explained variance (infamous R2)\n",
    "- the proportion to which a model accounts for the variation (dispersion) of data\n",
    "- scaled\n",
    "- 0 = chance, 1 = perfect\n",
    "- only compare on the same dataset\n",
    "\n",
    "MAPE is not symmetric\n",
    "- puts a heavier penalty on negative errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(pred, act):\n",
    "    return abs((pred - act) / act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mape(100, 90))\n",
    "print(mape(100, 110))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from common import load_iris\n",
    "\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting datasets (train or validation)\n",
    "\n",
    "Be careful with random sampling of datasets - **data leakage**\n",
    "- predicting the past from the future\n",
    "- duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_iris()\n",
    "\n",
    "x, y = ds.features, ds.target\n",
    "\n",
    "y = pd.DataFrame(data=np.argmax(y.values, axis=1), index=y.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set\n",
    "\n",
    "Let's follow a best practice and split off a test set.  Reason for this is:\n",
    "- unseen data for a final measure of generalization error\n",
    "- only ever do one forward pass on this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = train_test_split(x, y, test_size=0.1)\n",
    "assert x_tr.shape[0] > x_te.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "CV\n",
    "- use for hyperparams\n",
    "- use all your data for test & train\n",
    "- large K = small test set sizes\n",
    "- computationally expensive\n",
    "- avoid fitting your test set\n",
    "\n",
    "When not to randomly sample\n",
    "- time series\n",
    "\n",
    "Cross validation = randomly sample!\n",
    "- see [sklearn.model_selection.TimeSeriesSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html)\n",
    "\n",
    "Pick a model and do cross-validation.  Reasons for this:\n",
    "- use all data\n",
    "- don't overfit holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB(priors=[1/3 for _ in range(3)])\n",
    "\n",
    "#  defaults to stratified KFold\n",
    "results = cross_validate(\n",
    "    model, \n",
    "    x_tr, \n",
    "    y_tr.values.flatten(), \n",
    "    scoring='accuracy', \n",
    "    cv=5,\n",
    "    return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search + cross-validation\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "Most of the time these occur together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def make_prior(logits):\n",
    "    s = sum(logits)\n",
    "    return [e / s for e in logits]\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [1, 10, 100],\n",
    "    'max_features': [1, 2, 3]\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "gs = GridSearchCV(model, params, cv=5, return_train_score=True)\n",
    "gs.fit(x_tr, y_tr.values.reshape(-1, ))\n",
    "\n",
    "res = gs.cv_results_\n",
    "print(res.keys())\n",
    "\n",
    "res = pd.DataFrame(res)\n",
    "\n",
    "cols = [r for r in res.columns if ('score' in r and 'mean' in r)]\n",
    "\n",
    "print(np.max(res.loc[:, 'mean_test_score']))\n",
    "res.loc[:, cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random search + cross-validation\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\n",
    "\n",
    "Random search is better (so they say)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "params = {\n",
    "    'n_estimators': stats.randint(10, 1000),\n",
    "    'max_features': stats.randint(1, 3),\n",
    "    'max_depth': stats.randint(1, 30)\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "rs = RandomizedSearchCV(model, params, cv=5, return_train_score=True, n_iter=32)\n",
    "rs.fit(x_tr, y_tr.values.reshape(-1, ))\n",
    "\n",
    "res = rs.cv_results_\n",
    "res = pd.DataFrame(res)\n",
    "cols = [r for r in res.columns if ('score' in r and 'mean' in r)]\n",
    "print(np.max(res.loc[:, 'mean_test_score']))\n",
    "res.loc[:, cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A closer look at cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common import load_forest_fires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = load_forest_fires()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=50)\n",
    "\n",
    "x = forest.loc[:, ['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain']]\n",
    "y = forest.loc[:, 'area']\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "res = []\n",
    "for _ in range(10):\n",
    "    x, y = shuffle(x, y)\n",
    "    \n",
    "    results = cross_validate(\n",
    "        model, \n",
    "        x, \n",
    "        y.values.flatten(), \n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=3,\n",
    "        return_train_score=True\n",
    "    )\n",
    "\n",
    "    res.append(results['test_score'])\n",
    " \n",
    "res = pd.DataFrame(res)\n",
    "res.loc[:, 'avg'] = res.loc[:, :].mean(axis=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.min().min() ,res.max().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This noise is unavoidable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-variance tradeoff versus double descent\n",
    "\n",
    "[Belkin et. al (2019) Reconciling modern machine learning practice and the bias-variance trade-off](https://arxiv.org/pdf/1812.11118.pdf)\n",
    "\n",
    "Traditional wisdom is that beyond a certain amount of model capacity, additional capacity is used to overfit\n",
    "- the classical regime\n",
    "- sometimes, bigger models are worse\n",
    "\n",
    "Modern deep learning often shows the opposite\n",
    "- bigger models are better\n",
    "\n",
    "In late 2019 the **double descent** phenomena was observed\n",
    "- second regime (interpolating region) that occurs after a high capacity model has memorized the training data (interpolation threshold)\n",
    "\n",
    "Idea larger models are smoother\n",
    "- norms of coefficients are smaller\n",
    "\n",
    "> For smaller data sets, these\n",
    "large neural networks would be firmly in the over-parametrized regime, and simply training to\n",
    "obtain zero training risk often results in good test performance\n",
    "\n",
    "![](assets/belkin-f1.png)\n",
    "\n",
    "![](assets/belkin-f2.png)\n",
    "\n",
    "![](assets/belkin-f3.png)\n",
    "\n",
    "[Nakkiran et. al (2019) Deep Double Descent: Where Bigger Models and More Data Hurt](https://arxiv.org/pdf/1912.02292.pdf)\n",
    "\n",
    "Same thing but for deep neural nets (resnets + transformers)\n",
    "\n",
    "![](assets/Nakkiran-f1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
