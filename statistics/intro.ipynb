{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "\n",
    "> Much of basic statistics is not intuitive (or, at least, not taught in an intuitive fashion), and the opportunity for misunderstanding and error is massive. \n",
    ">\n",
    "> A strong course in applied statistics should cover basic hypothesis testing, regression, statistical power calculation, model selection, and a statistical programming language like R. \n",
    "> \n",
    "> *Statistics Done Wrong: The Woefully Complete Guide - Alex Reinhart*\n",
    "\n",
    "## This notebook\n",
    "\n",
    "This notebook is an introduction to a number of foundational concepts in statistics:\n",
    "\n",
    "- law of large numbers,\n",
    "- IID,\n",
    "- prediction versus inference,\n",
    "- what is a statistical analysis,\n",
    "- 80/20 data science,\n",
    "- Simpsons paradox,\n",
    "- Survivorship bias,\n",
    "- Pseudoreplication,\n",
    "- data fallacies.\n",
    "\n",
    "\n",
    "## Law of Large Numbers\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Law_of_large_numbers)\n",
    "\n",
    "The average of the results obtained from a large number of trials will be close to the expected value:\n",
    "- will tend to become closer as more trials are performed,\n",
    "- a small number of observations may not coincide with the expected value.\n",
    "\n",
    "[The Gambler's Fallacy](https://en.wikipedia.org/wiki/Gambler%27s_fallacy) \n",
    "\n",
    "- the mistaken belief that if something happens more frequently than normal during a given period, it will happen less frequently in the future (or vice versa),\n",
    "- a streak will not be immediately be \"balanced\",\n",
    "- this is a misunderstanding of independent probabilities.\n",
    "\n",
    "Joint probability of a & b is the product of their probabilities:\n",
    "\n",
    "$P(a, b) = P(a) * P(b)$\n",
    "\n",
    "## Independent and Identically Distributed (IID)\n",
    "\n",
    "Fundamental assumption made by statistical learning\n",
    "- assuming that the training set is **independently drawn** from a **fixed distribution**\n",
    "- **independent** = our samples are not correlated/related to each other\n",
    "- **identically distributed** = the distribution across our data set is the same as the 'true' distribution\n",
    "\n",
    "Random sampling is required to make sample representative (unbiased)\n",
    "- probability of sampling is independent\n",
    "\n",
    "## Parametric versus non-parametric models\n",
    "\n",
    "Fixed number of parameters = parametric\n",
    "- linear models, neural nets\n",
    "\n",
    "Variable number of parameters = non-parametric\n",
    "- support vector machines, K nearest neighbours\n",
    "- often the varying parameter is the number of samples\n",
    "\n",
    "### Question to class \n",
    "\n",
    "Are decision tree ensembles parametric or non-parametric?\n",
    "\n",
    "## Prediction versus inference\n",
    "\n",
    "[Stack exchange](https://stats.stackexchange.com/questions/244017/what-is-the-difference-between-prediction-and-inference)\n",
    "\n",
    "Prediction\n",
    "- predict what target will be for future features\n",
    "- given a new measurement, you want to use an existing data set to build a model that reliably chooses the correct identifier from a set of outcomes.\n",
    "\n",
    "Given some information on a Titanic passenger, you want to choose from the set {lives,dies} and be correct as often as possible. (See bias-variance tradeoff for prediction in case you wonder how to be correct as often as possible.)\n",
    "\n",
    "Inference\n",
    "- to infer how nature is associating the target to the features\n",
    "- given a set of data you want to infer how the output is generated as a function of the data.\n",
    "\n",
    "You want to find out what the effect of Age, Passenger Class and, Gender has on surviving the Titanic Disaster. You can put up a logistic regression and infer the effect each passenger characteristic has on survival rates.\n",
    "\n",
    "\n",
    "## Probability\n",
    "\n",
    "Chapter 3 of [Deep Learning](https://www.deeplearningbook.org/)\n",
    "\n",
    "Probability\n",
    "- extension of logic to deal with uncertainty\n",
    "- nearly all activities require reasoning under uncertainty\n",
    "\n",
    "Three sources of uncertanity\n",
    "1. stochastic environment\n",
    "2. incomplete observability - can't observe all relevant variables \n",
    "3. incomplete models that discard information\n",
    "\n",
    "It can be more practical to use **simple (yet inexact)** rules\n",
    "- 'most birds can fly' = cheap, simple & broadly applicable\n",
    "- 'birds fly, except for young birds & kiwis' = expensive, exact & brittle\n",
    "\n",
    "Heuristics reduce dimensionality --> low dimensional features \n",
    "- rule for crossing the street = is it big, is it moving \n",
    "\n",
    "Machine learning also reduces dimensionality\n",
    "- from business to a prediction that allows us to do control\n",
    "- control of a business objective\n",
    "\n",
    "## Frequentist or Bayesian perspective on probability\n",
    "\n",
    "**Frequentist** = frequency that an event would occur with\n",
    "- measurement of an expected probability\n",
    "\n",
    "**Bayesian** = degree of belief that an event will happen\n",
    "- prior + data -> posterior\n",
    "\n",
    "## Question to class\n",
    "\n",
    "Examples of a \n",
    "- frequentist probability\n",
    "- Bayesian probability \n",
    " \n",
    "## Decisions made in a statistical analysis\n",
    "\n",
    "Chapter 9 of [Statistics Done Wrong - Alex Reinhart](https://www.statisticsdonewrong.com/)\n",
    "\n",
    "- what to measure (labels)\n",
    "- what variables to use (features)\n",
    "- samples to drop (cleaning)\n",
    "- how to group\n",
    "- how to deal with missing data\n",
    "- how much data do I need\n",
    "\n",
    "Too much freedom = allows bias to creep in\n",
    "- commit to experiment setup before seeing the data i.e. a p-value threshold\n",
    "\n",
    "## Mistakes made in a statistical analysis\n",
    "\n",
    "Chapter 10 of [Statistics Done Wrong - Alex Reinhart](https://www.statisticsdonewrong.com/).\n",
    "\n",
    "> Surveys of statistically significant results reported in medical and psychological trials suggest that many p values are wrong and some statistically insignificant results are actually significant when computed correctly. \n",
    ">\n",
    "> Even the prestigious journal Nature isnâ€™t perfect, with roughly **38% of papers making typos and calculation errors in their p values**. \n",
    ">\n",
    ">Other reviews find examples of misclassified data, erroneous duplication of data, inclusion of the wrong dataset entirely, and other mix-ups, all concealed by papers that did not describe their analysis in enough detail for the errors to be easily noticed. \n",
    "\n",
    "## What to look for in a statistical analysis\n",
    "\n",
    "Chapter 12 of [Statistics Done Wrong - Alex Reinhart](https://www.statisticsdonewrong.com/).\n",
    "\n",
    "What is the statistical power of the study?\n",
    "\n",
    "How were features selected / discarded?\n",
    "\n",
    "Effect-size estimates and confidence intervals accompanying significance tests\n",
    "\n",
    "Showing whether the results have practical importance \n",
    "\n",
    "Whether appropriate statistical tests were used and how they were corrected for multiple comparisons \n",
    "\n",
    "## Relationship between quality & sharing\n",
    "\n",
    "Share your code & data!\n",
    "\n",
    "> Next Wicherts and his colleagues looked for a correlation between these errors and an unwillingness to share data. There was a clear relationship. \n",
    ">\n",
    "> Authors who refused to share their data were more likely to have committed an error in their paper, and their statistical evidence tended to be weaker. \n",
    "> \n",
    "> Because most authors refused to share their data, Wicherts could not dig for deeper statistical errors, and many more may be lurking. \n",
    "\n",
    "## 80/20 of data science\n",
    "\n",
    "Knowing when to use the mean versus median\n",
    "- always report both\n",
    "- the difference is a measure of skew\n",
    "\n",
    "**Knowing when the ranks matter versus when the absolute values matter**\n",
    "- can allow you to change a regression problem into a classification problem\n",
    "\n",
    "## How does bias change with more data?\n",
    "\n",
    "[Statistical Thinking for Data Science | SciPy 2015 | Chris Fonnesbeck](https://www.youtube.com/watch?v=TGGGDpb04Yc)\n",
    "\n",
    "Bias = systematic error \n",
    "- wrong in the same direction all the time\n",
    "\n",
    "How does sample size changes bias?\n",
    "- imagine we induce bias intentionally by ignoring negative values 50% of the time\n",
    "- bias gets worse as sample size increases\n",
    "- highly precise wrong answers\n",
    "\n",
    "## Simpsons Paradox\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Simpson%27s_paradox)\n",
    "\n",
    "Trend appearing in several different groups that reverses when groups are combined\n",
    "\n",
    "![](./assets/si.gif)\n",
    "\n",
    "#### Kidney stone treatment\n",
    "This is a real-life example from a medical study comparing the success rates of two treatments for kidney stones.\n",
    "\n",
    "\n",
    "The table below shows the success rates and numbers of treatments for treatments involving both small and large kidney stones, where Treatment A includes all open surgical procedures and Treatment B involves only a small puncture. The numbers in parentheses indicate the number of success cases over the total size of the group.\n",
    "\n",
    "![](./assets/simpson-kidney.png)\n",
    "\n",
    "The paradoxical conclusion is that treatment A is more effective when used on small stones, and also when used on large stones, yet treatment B is more effective when considering both sizes at the same time. In this example, the \"lurking\" variable is the severity of the case (represented by the doctors' treatment decision trend of favoring B for less severe cases).\n",
    "When the less effective treatment (B) is applied more frequently to less severe cases, it can appear to be a more effective treatment.\n",
    "\n",
    "## Survivorship bias\n",
    "\n",
    "[Statistical Thinking for Data Science | SciPy 2015 | Chris Fonnesbeck](https://www.youtube.com/watch?v=TGGGDpb04Yc)\n",
    "\n",
    "Cat survivorship numbers being higher [NY Times](https://www.nytimes.com/1989/08/22/science/on-landing-like-a-cat-it-is-a-fact.html\n",
    ")\n",
    "\n",
    ">From June 4 through Nov. 4, 1984, for instance, 132 such victims were admitted to the Animal Medical Center on 62d Street in Manhattan.\n",
    "Most of the cats landed on concrete. Most survived. Experts believe they were able to do so because of the laws of physics, superior balance and what might be called the flying-squirrel tactic.\n",
    "Even more surprising, the longer the fall, the greater the chance of survival. Only one of 22 cats that plunged from above 7 stories died, and there was only one fracture among the 13 that fell more than 9 stories. The cat that fell 32 stories on concrete, Sabrina, suffered a mild lung puncture and a chipped tooth. She was released from the hospital after 48 hours.\n",
    "\n",
    "Survivorship\n",
    "- found data\n",
    "- conveinent data\n",
    "- only see winners, odds are distorted, because failures are excluded\n",
    "- is the missing data related to the target?\n",
    "\n",
    "Self selection bias\n",
    "- can choose to report data or not\n",
    "\n",
    "## The Baltimore stockbroker\n",
    "\n",
    "Chapter 6 of [How Not to Be Wrong: The Power of Mathematical Thinking - Jordan Ellenberg](https://en.wikipedia.org/wiki/How_Not_to_Be_Wrong).\n",
    "\n",
    "You recieve mail from a stockbroker who correctly predicts the movement of stock prices\n",
    "- this continues for 10 weeks\n",
    "\n",
    "We can calculate the probability of this happening:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0009765625"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5 ** 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we instead look at it from the stockbrokers perspective\n",
    "- send 10,240 letters in the first week\n",
    "- send 5,120 in the second (to those who we got the first week correct)\n",
    "- continue for 10 weeks, and we have 10 people who have recieved perfect predictions\n",
    "\n",
    "The key is to understand how many chances did the stockbroker have\n",
    "- not only the probablility of success\n",
    "\n",
    "Improbable things happen a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10240 * 0.5 ** 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudoreplication\n",
    "\n",
    "[Chapter 3 of Statistics Done Wrong - Alex Reinhart](https://www.statisticsdonewrong.com/)\n",
    "\n",
    "Counting the same sample multiple times\n",
    "- dependence is the problem here (non independent aka biased sampling)\n",
    "\n",
    "Additional measurements that depend on previous data don't prove your results generalize \n",
    "- they only increase certainty about specific sample studied\n",
    "\n",
    "Eliminate hidden sources of correlation between variables\n",
    "- measure 1,000 patients rather than 100 patients 10 times\n",
    "- 100's neurons in two animals\n",
    "- comparing growth rates of different crops in different fields\n",
    "\n",
    "Solutions\n",
    "- average dependent data points \n",
    "- analyze each point separately - don't combine, analyze only a subset (ie day 5)\n",
    "\n",
    "Doing PCA on different batches of results\n",
    "- if the number of the batch is important (i.e batch_index), then you have problems with the distribution for each time\n",
    "\n",
    "## Data fallacies\n",
    "\n",
    "[Survivorship bias](https://medium.com/@penguinpress/an-excerpt-from-how-not-to-be-wrong-by-jordan-ellenberg-664e708cfc3d)\n",
    "- Abraham Wald in WW2\n",
    "- intitution to place armor on planes where the most bullets are = wrong!\n",
    "- place armor where there are no bullet holes - because these planes didn't come back\n",
    "- *How Not To Be Wrong by Jordan Ellenberg*\n",
    "\n",
    "[Cobra effect](https://en.wikipedia.org/wiki/Cobra_effect)\n",
    "- bounty on dead Cobras in British colonial India\n",
    "- people breed cobras for the bounty\n",
    "\n",
    "<img src=\"assets/fallacies.jpg\" alt=\"\" width=\"900\"/>\n",
    "\n",
    "## Quiz\n",
    "\n",
    "What does IID stand for?\n",
    "\n",
    "What is a parametric model?  What is a non-parametric model?\n",
    "\n",
    "Three sources of uncertantity?\n",
    "\n",
    "Difference between Frequentist & Bayesian probability?\n",
    "\n",
    "How does bias change as we add data?\n",
    "\n",
    "What is Simpson's Paradox?\n",
    "\n",
    "What is survivorship bias?\n",
    "\n",
    "What is psuedoreplication?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
