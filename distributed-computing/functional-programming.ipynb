{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Programming \n",
    "\n",
    "Functional programming in Python:\n",
    "\n",
    "- map,\n",
    "- lazy computation,\n",
    "- lambda functions,\n",
    "- filter,\n",
    "- reduce.\n",
    "\n",
    "Three things:\n",
    "\n",
    "1. no side effects,\n",
    "2. variables don't vary / immutable data,\n",
    "3. first class functions - no objects and no state,\n",
    "\n",
    "\n",
    "## Resources\n",
    "\n",
    "[Functional Programming in Python\n",
    "By Marcus Sanatan](https://stackabuse.com/functional-programming-in-python/)\n",
    "\n",
    "[Clean Architecture - Uncle Bob Martin](https://www.amazon.co.uk/Clean-Architecture-Craftsmans-Software-Structure/dp/0134494164)\n",
    "\n",
    "[What is Functional Programming? - Scott Murphy](https://www.youtube.com/watch?v=KHojnWHemO0)\n",
    "\n",
    "## What is functional programming?\n",
    "\n",
    "Three things:\n",
    "\n",
    "1. no side effects,\n",
    "2. variables don't vary / immutable data,\n",
    "3. first class functions - no objects and no state,\n",
    "\n",
    "Examples of functional programming languages include Lisp, Haskell, Erlang, Clojure.\n",
    "\n",
    "Also a useful idea when thinking about implementations\n",
    "\n",
    "[John Carmack (on Parallel Implementations)](http://sevangelatos.com/john-carmack-on-parallel-implementations/) notes it is eaiser to switch out implementations if ideas are expressed as pure functions.  Internal state & multiple entry points make programming harder.\n",
    "\n",
    "## 1. No side effects\n",
    "\n",
    "- same inputs -> same outputs - always,\n",
    "- idempotent - things always run / perform the same way,\n",
    "- no dependency on the state of the outside world.\n",
    "\n",
    "Not doing something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(data):\n",
    "    new_data = clean(data)\n",
    "    database.save(new_data)\n",
    "    database.load(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Variables that don't vary / Immutable data\n",
    "\n",
    "Variables are only initialized:\n",
    "\n",
    "- they are never changed,\n",
    "- this avoids problems such as race conditions / deadlocks.\n",
    "\n",
    "Variables being immutable means we can't do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  can't do this - mutates the object in place\n",
    "def f(x):\n",
    "    x += 1\n",
    "    return x\n",
    "\n",
    "#  can do this - creates a new object\n",
    "def f(x):\n",
    "    x = x + 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Functions are first class\n",
    "\n",
    "First class citizens means we can pass functions around like other variables (also known as higher order functions).\n",
    "\n",
    "Below we pass the `sum` function into a generic `reducer` function (there is no Python built-in for reduce):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducer(func, data):\n",
    "    return func(data)\n",
    "\n",
    "data = [1, 2, 3]\n",
    "reducer(sum, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing in another function (`len`) gives different results - the length of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer(len, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map\n",
    "\n",
    "Applying a function to each element of an iterable - similar to `df.apply` in pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower(s):\n",
    "    return s.lower()\n",
    "\n",
    "cities = ['Berlin', 'Auckland', 'London', 'Sheffield']\n",
    "m = map(lower, cities)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Python has returned a map object, not the transformed data.  This is an example of **lazy computation**, which is a two step process:\n",
    "1. build a pipeline/graph\n",
    "\n",
    "2. put data through it when needed\n",
    "\n",
    "Examples include Tensorflow 1, Spark, Python generators.\n",
    "\n",
    "We can get the next element as we would for any kind of generator:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are more impatient than lazy, we can get all the processed data by calling `list` on the generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(lower, cities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda functions\n",
    "\n",
    "Anonymous = the function is not assigned to a variable. In Python we can have objects with no variable reference (until they get garbage collected :)\n",
    "\n",
    "We can do the same example as above using a lambda function (which is anonmyous):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(lambda x: x.lower(), cities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object we define above is a lambda function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = lambda x: x.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do more complex things in lambdas, such as accessing elements of the input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "populations = [\n",
    "    ('Berlin', 3.7, 'eu'),\n",
    "    ('Auckland', 1.7, 'pac'),\n",
    "    ('London', 8.9, 'eu'),\n",
    "    ('Sheffield', 0.5, 'eu')\n",
    "]\n",
    "\n",
    "list(map(lambda x: (x[0], x[1] * 1000), populations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have total flexibility in **what data structure** we use in the iterable, and **how we interact with it** in the lambda.  We have decomposed and separated the data from the behaviour!\n",
    "\n",
    "We could map over a sequence of namedtuples, and access elements using the attribute `.` syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "pop = namedtuple('city', ['city', 'population', 'continent'])\n",
    "\n",
    "populations = [pop(*p) for p in populations]\n",
    "\n",
    "list(map(lambda x: (x.city, x.population * 1000), populations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce\n",
    "\n",
    "Reduce will aggregate a sequence to single values (either a single value for the entire sequence, or one single value per group).  Also known as aggregation or a groupby.\n",
    "\n",
    "Above we defined a function `reducer` to demonstrate that functions are first class citizens in Python.  \n",
    "\n",
    "The Python standard library also has it's own reduce function - `functools.reduce`.  This function operates on each element and accumulates, returning a single aggregated example.\n",
    "\n",
    "We can use this `reduce` function on our `populations` dataset:\n",
    "\n",
    "- define a lambda function that adds on the population of the sequence to the total,\n",
    "- our sequence populations,\n",
    "- an initial value of `0`.\n",
    "\n",
    "This is how we would do this in normal Python - iterate over the list and increment a float:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for p in populations:\n",
    "    total += p.population\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equivilant using `functools.reduce`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "reduce(lambda total, pop: total + pop[1], populations, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use this `reduce` function to groupby continent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb(acc, city):\n",
    "    acc[city.continent].append(city.city)\n",
    "    return acc\n",
    "\n",
    "reduce(\n",
    "    gb,\n",
    "    populations,\n",
    "    {'eu': [], 'pac': []}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter\n",
    "\n",
    "Tests each element, keeps those that pass - similar to boolean masking in pandas/numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(filter(lambda x: x[1] > 1.0, populations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical\n",
    "\n",
    "Create a data processing pipeline that selects the cities that have populations greater than the average of all cities\n",
    "\n",
    "Two steps:\n",
    "1. `reduce` to find the average of all cities,\n",
    "2. `filter` to select using cities above that average.\n",
    "\n",
    "This can be done in a single reduce step - suggest first getting the two step solution working :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical\n",
    "\n",
    "Implement the same pipeline using two list comprehensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "In Python, any combination of `map` & `filter` can be done with a single list comprehension - why do we need to use two in the example above?\n",
    "\n",
    "## Practical\n",
    "\n",
    "Create a data processing pipeline that finds the average population for both continents:\n",
    "1. reduce to (key, (populations)),\n",
    "2. map from (key, (populations)) to (key, avg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
