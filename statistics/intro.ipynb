{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "\n",
    "This notebook outlines a few background concepts before we dig into the course proper.\n",
    "\n",
    "> Much of basic statistics is not intuitive (or, at least, not taught in an intuitive fashion), and the opportunity for misunderstanding and error is massive. \n",
    ">\n",
    "> A strong course in applied statistics should cover basic hypothesis testing, regression, statistical power calculation, model selection, and a statistical programming language like R. \n",
    "> \n",
    "> *Statistics Done Wrong: The Woefully Complete Guide - Alex Reinhart*\n",
    "\n",
    "## Law of Large Numbers\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Law_of_large_numbers)\n",
    "\n",
    "The average of the results obtained from a large number of trials should be close to the expected value\n",
    "- will tend to become closer as more trials are performed\n",
    "- a small number of observations may not coincide with the expected value\n",
    "- a streak of one value will not be immediately be \"balanced\" by the others \n",
    "\n",
    "[The gambler's fallacy](https://en.wikipedia.org/wiki/Gambler%27s_fallacy) \n",
    "- the mistaken belief that if something happens more frequently than normal during a given period\n",
    "- it will happen less frequently in the future (or vice versa)\n",
    "\n",
    "## Independent and Identically Distributed (IID)\n",
    "\n",
    "Fundamental assumption made in statistical learning\n",
    "- assuming that the training set is independently drawn from a fixed distribution\n",
    "- **independent** = our samples are not correlated/related to each other\n",
    "- **identically distributed** = the distribution across our data set is the same as the 'true' distribution\n",
    "\n",
    "Random sampling is required to make sample representative\n",
    "\n",
    "## Parametric versus non-parametric models\n",
    "\n",
    "Fixed number of parameters = parametric\n",
    "- neural nets\n",
    "\n",
    "Variable number of parameters = non-parametric\n",
    "- support vector machines, K nearest neighbours\n",
    "- often the varying parameter is the number of samples\n",
    "\n",
    "## Probability\n",
    "\n",
    "Chapter 3 of [Deep Learning](https://www.deeplearningbook.org/).\n",
    "\n",
    "Probability = extension of logic to deal with uncertantity.  Nearly all activities require reasoning under uncertantity.  \n",
    "\n",
    "Three sources of uncertantity\n",
    "1. stochastic environment\n",
    "2. incomplete observation\n",
    "3. incomplete models (that discard infomation)\n",
    "\n",
    "More practical to use simple (yet inexact) rules\n",
    "- 'most birds can fly' = cheap, simple & broadly applicable\n",
    "- 'birds fly, except for young birds & kiwis' = expensive, exact & brittle\n",
    "\n",
    "**Frequentist** probability = represent the frequency that an event would occur with\n",
    "- rolling dice, counting cards\n",
    "\n",
    "**Bayesian** probability = represents a degree of belief\n",
    "- quantifying a level of certantity\n",
    "\n",
    "## Decisions made in a statistical analysis\n",
    "\n",
    "Chapter 9 of [Statistics Done Wrong - Alex Reinhart](https://www.statisticsdonewrong.com/).\n",
    "\n",
    "- what to measure (labels)\n",
    "- what variables to use (features)\n",
    "- samples to drop (cleaning)\n",
    "- how to group\n",
    "- how to deal with missing data\n",
    "- how much data do I need\n",
    "\n",
    "Too much freedom = allows bias to creep in\n",
    "- commit to decisions before seeing the data\n",
    "- i.e. a p-value threshold\n",
    "\n",
    "## Mistakes made in a statistical analysis\n",
    "\n",
    "Chapter 10 of [Statistics Done Wrong - Alex Reinhart](https://www.statisticsdonewrong.com/).\n",
    "\n",
    "> Surveys of statistically significant results reported in medical and psychological trials suggest that many p values are wrong and some statistically insignificant results are actually significant when computed correctly. \n",
    ">\n",
    "> Even the prestigious journal Nature isnâ€™t perfect, with roughly **38% of papers making typos and calculation errors in their p values**. \n",
    ">\n",
    ">Other reviews find examples of misclassified data, erroneous duplication of data, inclusion of the wrong dataset entirely, and other mix-ups, all concealed by papers that did not describe their analysis in enough detail for the errors to be easily noticed. \n",
    "\n",
    "## What to look for in a statistical analysis\n",
    "\n",
    "Chapter 12 of [Statistics Done Wrong - Alex Reinhart](https://www.statisticsdonewrong.com/).\n",
    "\n",
    "What is the statistical power of the study?\n",
    "\n",
    "How were features selected / discarded?\n",
    "\n",
    "Effect-size estimates and confidence intervals accompanying significance tests, showing whether the results have practical importance \n",
    "\n",
    "Whether appropriate statistical tests were used and how they were corrected for multiple comparisons \n",
    "\n",
    "## Relationship between quality & sharing\n",
    "\n",
    "Share your code & data!\n",
    "\n",
    "> Next Wicherts and his colleagues looked for a correlation between these errors and an unwillingness to share data. There was a clear relationship. \n",
    ">\n",
    "> Authors who refused to share their data were more likely to have committed an error in their paper, and their statistical evidence tended to be weaker. \n",
    "> \n",
    "> Because most authors refused to share their data, Wicherts could not dig for deeper statistical errors, and many more may be lurking. \n",
    "\n",
    "## 80/20 of data science\n",
    "\n",
    "Knowing when to use the mean versus median\n",
    "- always report both\n",
    "\n",
    "Knowing when the ranks matter versus when the absolute values matter\n",
    "- can allow you to change a regression problem into a classification problem\n",
    "\n",
    "## How does bias change with more data?\n",
    "\n",
    "[Statistical Thinking for Data Science | SciPy 2015 | Chris Fonnesbeck](https://www.youtube.com/watch?v=TGGGDpb04Yc)\n",
    "\n",
    "Bias = systematic error (wrong in the same direction all the time)\n",
    "\n",
    "Does experiment looking at how sample size changes bias (min 8)\n",
    "- induces bias intentionally by ignoring negative values 50% of the time\n",
    "- shows that bias gets worse with sample size!\n",
    "- highly precise wrong answers\n",
    "\n",
    "## Simpsons paradox\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Simpson%27s_paradox)\n",
    "\n",
    "Trend appearing in several different groups that reverses when groups are combined\n",
    "\n",
    "![](./assets/si.gif)\n",
    "\n",
    "Study of gender bias among graduate school admissions to University of California, Berkeley. The admission figures for the fall of 1973:\n",
    "\n",
    "![](./assets/simpson1.png)\n",
    "\n",
    "The figures indicate that men are less likely to be admitted.  The effect is unlikely to be due to chance.\n",
    "\n",
    "But if we examine the six largest departments:\n",
    "\n",
    "![](./assets/simpson2.png)\n",
    "\n",
    "Bickel et. al (1975) concluded\n",
    "- women tended to apply for competitive departments with lowel admission rates (English)\n",
    "- men apply for less competitive departments with high rates of admission (engineering, chemistry)\n",
    "\n",
    "I think it is more a commentary on lack of funding (more funding = less competition)\n",
    "\n",
    "## Survivorship bias\n",
    "\n",
    "[Statistical Thinking for Data Science | SciPy 2015 | Chris Fonnesbeck](https://www.youtube.com/watch?v=TGGGDpb04Yc)\n",
    "\n",
    "Cat survivorship numbers being higher [NY Times](https://www.nytimes.com/1989/08/22/science/on-landing-like-a-cat-it-is-a-fact.html\n",
    ")\n",
    "\n",
    ">>>\n",
    "From June 4 through Nov. 4, 1984, for instance, 132 such victims were admitted to the Animal Medical Center on 62d Street in Manhattan.\n",
    "Most of the cats landed on concrete. Most survived. Experts believe they were able to do so because of the laws of physics, superior balance and what might be called the flying-squirrel tactic.\n",
    "Even more surprising, the longer the fall, the greater the chance of survival. Only one of 22 cats that plunged from above 7 stories died, and there was only one fracture among the 13 that fell more than 9 stories. The cat that fell 32 stories on concrete, Sabrina, suffered a mild lung puncture and a chipped tooth. She was released from the hospital after 48 hours.\n",
    ">>>\n",
    "\n",
    "Survivorship\n",
    "- found data\n",
    "- conveinent data\n",
    "- is the missing data related to the target?\n",
    "\n",
    "Self selection bias\n",
    "- can choose to report data or not\n",
    "\n",
    "## The Baltimore stockbroker\n",
    "\n",
    "Chapter 6 of [How Not to Be Wrong: The Power of Mathematical Thinking - Jordan Ellenberg](https://en.wikipedia.org/wiki/How_Not_to_Be_Wrong).\n",
    "\n",
    "You recieve mail from a stockbroker who correctly predicts the movement of stock prices\n",
    "- this continues for 10 weeks\n",
    "\n",
    "We can calculate the probability of this happening:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.5 ** 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we instead look at it from the stockbrokers perspective\n",
    "- send 10,240 letters in the first week\n",
    "- send 5,120 in the second (to those who we got the first week correct)\n",
    "- continue for 10 weeks, and we have 10 people who have recieved perfect predictions\n",
    "\n",
    "The key is to understand how many chances did the stockbroker have\n",
    "- not only the probablility\n",
    "\n",
    "Improbable things happen a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10240 * 0.5 ** 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudoreplication\n",
    "\n",
    "[Chapter 3 of Statistics Done Wrong - Alex Reinhart](https://www.statisticsdonewrong.com/)\n",
    "\n",
    "Counting the same sample multiple times\n",
    "- dependence is the problem here (non independent sampling)\n",
    "\n",
    "Additional measurements that depend on previous data don't prove your results generalize \n",
    "- they only increase certainty about specific sample studied\n",
    "\n",
    "Eliminate hidden sources of correlation between variables\n",
    "- meausure 1,000 paitients rather than 100 paitents 10 times\n",
    "- 100's neurons in two animals\n",
    "- comparing growth rates of different crops in different fields\n",
    "\n",
    "Solutions\n",
    "- average dependent data points \n",
    "- analyze each point separately - don't combine, analyze only a subset (ie day 5)\n",
    "\n",
    "Doing PCA on different batches of results\n",
    "- if the number of the batch is important, then you have problems with the distribution for each time\n",
    "\n",
    "\n",
    "## Data fallacies\n",
    "\n",
    "<img src=\"assets/fallacies.jpg\" alt=\"\" width=\"900\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
