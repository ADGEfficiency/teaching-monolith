{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions\n",
    "\n",
    "See Chapter 2-4 & 6 of [Think Stats 2nd Edition](https://greenteapress.com/wp/think-stats-2e/).\n",
    "\n",
    "In this notebook we wil be working with tensors of at two dimensions (batch_size, num_features).  \n",
    "\n",
    "This is to get you used to the idea of having multiple samples in a single array (when training neural networks your `x_train`, `y_train` will have at leat two dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from common import make_pmf, make_cdf, percentile, percentile_rank\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample data from **two normal** distributions and **two uniform** distributions (four in total):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = np.random.normal((10, 10), (10, 20), size=(1000, 2)).astype(int)\n",
    "\n",
    "uniform = np.random.uniform(low=-50, high=50, size=(1000, 2)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central tendency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **mean** is also known as the **expected value** (*on expectation* == on average):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(normal, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **median** is a percentile based statistic (more on them later) and is informative when you have outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(normal, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between the mean & median can characterize skew:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(normal, axis=0) - np.median(normal, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spread / variability of the data\n",
    "\n",
    "**Variance** - how far away a variable is from its mean:\n",
    "\n",
    "$$ \\sigma^2_x = \\frac{1}{n} \\sum(x_n - \\mu_x)^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(uniform, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard deviation** - square root of the variance (in the same units as the data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  test that var^2 == standard deviation\n",
    "assert (np.sqrt(np.var(uniform, axis=0)) == np.std(uniform, axis=0)).all()\n",
    "\n",
    "np.std(uniform, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram\n",
    "\n",
    "We can use a **histogram** to show shape & outliers (the histogram performs binning on our continuous variables):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.hist(normal)\n",
    "f = plt.ylabel('frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.hist(uniform)\n",
    "_ = plt.ylabel('frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms can also compare distributions (note that we have four!):\n",
    "- but if our variables have different ranges, it can be hard to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.hist(normal)\n",
    "f = plt.hist(uniform)\n",
    "_ = plt.ylabel('frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability mass functions (PMF)\n",
    "\n",
    "The PMF is a simple **normalizing of the counts** of discrete bins:\n",
    "- this makes the y-axis comparable \n",
    "- look at `make_pmf` definition in `common.py`\n",
    "\n",
    "Problems with PMFs:\n",
    "- the more values we have, the smaller their probabilities become (and the larger the effect of noise on the probabilites)\n",
    "- even with the correct scale, it is still hard to compare distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(*make_pmf(normal[:, 0]))\n",
    "plt.bar(*make_pmf(uniform[:, 0]))\n",
    "_ = plt.ylabel('probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentile rank\n",
    "\n",
    "Value & samples -> **percentile rank**\n",
    "\n",
    "90th percentile = a value that is higher than 90% of the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array([55, 77, 88, 66, 99])\n",
    "value = 66\n",
    "\n",
    "percentile_rank(value, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative distribution functions (CDF)\n",
    "\n",
    "The CDF is a function that maps from **value -> normalized percentile rank** (in the range of 0 to 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = [(percentile_rank(v, values), v) for v in values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then evaluate the CDF for any value of x using our percentile rank function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_rank(0, normal[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot a CDF for two of our distributions.  We can see:\n",
    "- the range (min & max)\n",
    "- the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x = zip(*make_cdf(normal[:, 0]))\n",
    "plt.plot(x, y, label='normal')\n",
    "\n",
    "y, x = zip(*make_cdf(uniform[:, 0]))\n",
    "plt.plot(x, y, label='uniform')\n",
    "plt.ylabel('cumulative %')\n",
    "\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantiles\n",
    "\n",
    "Above we have mapped from \n",
    "- value & samples -> percentile rank\n",
    "\n",
    "Let's now do the opposite \n",
    "- **percentile rank & samples -> value**\n",
    "\n",
    "One example of a percentile based statistic is the median (measuring the central tendency of the distribution):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile(0.5, normal[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(normal[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also useful are other percentile based statistics such as the **interquartile range (IQR)**, which is the difference between the 75th and 25th percentiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile(0.75, normal[:, 0]) - percentile(0.25, normal[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also common are **quantiles** - equally spaced points in the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(percentile(0.25, normal[:, 0]), percentile(0.5, normal[:, 0]), percentile(0.75, normal[:, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from CDFs\n",
    "\n",
    "Because the distribution of percentile ranks is uniform, we can eaisly sample from a CDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.hist(\n",
    "    [percentile(s, normal[:, 0]) for s in np.random.uniform(0, 1, 500)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing percentile ranks\n",
    "\n",
    "We can compare values from one distribution with another - for example our two normal distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = 10\n",
    "\n",
    "rank = percentile_rank(value, normal[:, 0])\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile(rank, normal[:, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
