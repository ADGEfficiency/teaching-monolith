{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `multiprocessing`\n",
    "\n",
    "Parallel computation on a single machine in Python\n",
    "- one of my most important tools\n",
    "- Python standard library\n",
    "\n",
    "\n",
    "## Python standard library parallel computation ecosystem\n",
    "\n",
    "[Multiprocessing Vs. Threading In Python - Sid Panjwani](https://timber.io/blog/multiprocessing-vs-multithreading-in-python-what-you-need-to-know/)\n",
    "\n",
    "`threading` - uses threads (same memory space)\n",
    "- helps with network issues\n",
    "\n",
    "`multiprocessing` - uses processes (different memory space)\n",
    "- help with compute issues\n",
    "\n",
    "How does this relate to CPU cores\n",
    "- CPU cores are fixed (usually 4-16 in laptops - depends on your physical hardware)\n",
    "- more cores = true parallelism (opposed to the very fast task switching done by the OS)\n",
    "- your computer can have many threads and many processes (depends on the OS)\n",
    "- the OS will schedule these threads/processes to available cores\n",
    "- a single thread consumes an entire core\n",
    "\n",
    "[Multithreading and multicore differences](https://stackoverflow.com/questions/11835046/multithreading-and-multicore-differences)\n",
    "\n",
    "*But my CPU core has two threads*\n",
    "- this is a different use of the term (the hardware thread)\n",
    "- CPU having threads allows a core to run thread in parallel, as if there were multiple cores\n",
    "- known as hyperthreading\n",
    "\n",
    "\n",
    "## Why do we need `multiprocessing`?\n",
    "\n",
    "Python has a Global Interpreter Lock (GIL) that prevents parallelizing computation across multiple cores\n",
    "- Python is not thread safe\n",
    "- requires a lock when accessing an object (a form of memory management)\n",
    "\n",
    "\n",
    "## What can be hard in multiprocessing?\n",
    "\n",
    "Sharing things between processes\n",
    "- solution = don't use it in this way\n",
    "- make every process independent\n",
    "- a functional style = no interaction (because interaction = side effects!)\n",
    "\n",
    "\n",
    "## `multiprocessing` 101\n",
    "\n",
    "We map functions to data\n",
    "- but in parallel!\n",
    "\n",
    "First let's do a simple `map` in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.173375129699707\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def subtract(x, sleep=0.01):\n",
    "    time.sleep(sleep)\n",
    "    return x*x\n",
    "\n",
    "data = np.random.uniform(0, 100, size=100).tolist()\n",
    "st = time.time()\n",
    "\n",
    "result = list(map(subtract, data))\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's parallelize this using `multiprocessing`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24825763702392578\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "num_process = 8\n",
    "st = time.time()\n",
    "\n",
    "with Pool(num_process) as pool:\n",
    "    out = pool.map(subtract, data)\n",
    "    \n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common use case is to have arguments for the function being mapped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.675908088684082\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "st = time.time()\n",
    "with Pool(num_process) as p:\n",
    "    rewards = p.map(partial(subtract, sleep=0.1), data)\n",
    "    \n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when we remove our sleep, the non-mulitprocessing `map` is faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006787776947021484\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "result = list(map(partial(subtract, sleep=0.0), data))\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed computation has overhead (fixed + variable) \n",
    "- make sure your function runs long enough to justify it\n",
    "\n",
    "## Exercise - bitcoin mining\n",
    "\n",
    "Write multiprocessed code to solve a hashing problem (similar to how *proof of work* works in Bitcoin)\n",
    "- take a given input string (base string)\n",
    "- add strings on the end of it until you get a hash with a leading `0`\n",
    "\n",
    "We can hash in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'928581169'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from zlib import adler32\n",
    "str(adler32('I miss DSR already'.encode()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add characters onto the end of this string and we will get a different hash:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1034618450'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(adler32('I miss DSR already!'.encode()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few ways to solve this - one is to write a function that:\n",
    "- randomly selects n characters\n",
    "- adds those characters onto the string\n",
    "- if the hash starts with 1, return the characters & a success code\n",
    "- otherwise return the characters and a failure code\n",
    "\n",
    "This function can be run in parallel :)\n",
    "\n",
    "1. write the function\n",
    "2. normal `map`\n",
    "3. multiprocess :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "base_string = 'I miss DSR already'\n",
    "alpha = string.ascii_lowercase\n",
    "\n",
    "def check_string(stri):\n",
    "    ha = str(adler32(stri.encode()))\n",
    "    \n",
    "base = 'I miss DSR already'\n",
    "for _ in range(100):\n",
    "    import random\n",
    "    new = random.choice(alpha)\n",
    "    check_string(base + new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25, 0.2 , 0.2 , 0.2 , 0.2 , 0.4 , 0.3 , 0.2 , 0.2 , 0.15, 0.2 ,\n",
       "       0.2 , 0.2 , 0.1 , 0.2 , 0.4 , 0.4 , 0.25, 0.3 , 0.3 , 0.2 , 0.4 ,\n",
       "       0.2 , 0.5 , 0.2 , 0.2 , 0.4 , 0.2 , 0.2 , 0.2 , 0.2 , 0.4 , 0.1 ,\n",
       "       0.2 , 0.15, 0.2 , 0.2 , 0.1 , 0.2 , 0.2 , 0.3 , 0.3 , 0.2 , 0.6 ,\n",
       "       0.4 , 0.2 , 0.2 , 0.2 , 0.2 , 0.2 , 1.4 , 1.5 , 1.5 , 1.3 , 1.5 ,\n",
       "       1.3 , 1.6 , 1.  , 1.3 , 1.4 , 1.  , 1.5 , 1.  , 1.4 , 1.3 , 1.4 ,\n",
       "       1.5 , 1.  , 1.5 , 1.1 , 1.8 , 1.3 , 1.5 , 1.2 , 1.3 , 1.4 , 1.4 ,\n",
       "       1.7 , 1.5 , 1.  , 1.1 , 1.  , 1.2 , 1.6 , 1.5 , 1.6 , 1.5 , 1.3 ,\n",
       "       1.3 , 1.3 , 1.2 , 1.4 , 1.2 , 1.  , 1.3 , 1.2 , 1.3 , 1.3 , 1.1 ,\n",
       "       1.3 , 2.5 , 1.9 , 2.1 , 1.8 , 2.2 , 2.1 , 1.7 , 1.8 , 1.8 , 2.5 ,\n",
       "       2.  , 1.9 , 2.1 , 2.  , 2.4 , 2.3 , 1.8 , 2.2 , 2.3 , 1.5 , 2.3 ,\n",
       "       2.  , 2.  , 1.8 , 2.3 , 1.8 , 1.8 , 1.8 , 2.15, 1.6 , 1.9 , 2.  ,\n",
       "       2.15, 1.5 , 1.4 , 2.3 , 2.4 , 1.8 , 1.8 , 2.1 , 2.4 , 2.3 , 1.9 ,\n",
       "       2.3 , 2.3 , 2.3 , 1.9 , 2.  , 2.3 , 1.8 ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()['data']\n",
    "import numpy as np\n",
    "\n",
    "ss\n",
    "x = np.random.normal(0, 1, size=size)\n",
    "y = data[:, -1]\n",
    "\n",
    "tree.fit(x, y)\n",
    "pred = tree.predict(x)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
