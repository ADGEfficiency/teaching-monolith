{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import sem as scipy_standard_error\n",
    "\n",
    "from common import make_cdf, percentile_rank, load_forest_fires\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Estimation\n",
    "\n",
    "See Chapter 8 of [Think Stats 2nd Edition](https://greenteapress.com/wp/think-stats-2e/), Chapter 2 of [Practical Statistics for Data Scientists](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/).\n",
    "\n",
    "## What do we want to estimate?\n",
    "\n",
    "[Estimator - Wikipedia](https://en.wikipedia.org/wiki/Estimator)\n",
    "\n",
    "We want to estimate statistics.  Why?  Statistics allow us to measure, model and compare.\n",
    "\n",
    "A statistic is a summary of the data\n",
    "- mean\n",
    "- min\n",
    "- max\n",
    "- variance\n",
    "\n",
    "## How can we estimate?\n",
    "\n",
    "By sampling!\n",
    "- we will never have the entire population\n",
    "\n",
    "An (insufficient) definition of statistics = making inference from samples to populations\n",
    "\n",
    "We often make use of statistics drawn from samples\n",
    "- these statistics will be different than the statistics of the entire population\n",
    "\n",
    "The distribution of a given statistic is known as a **sampling distribution** - more on that later.  \n",
    "\n",
    "## Three sources of error in estimation\n",
    "\n",
    "How can we make mistakes in estimating statistics?\n",
    "\n",
    "**Sampling bias**\n",
    "- samples having different probabilities than others\n",
    "- non-random sampling\n",
    "\n",
    "**Sampling error**\n",
    "- arises from using statistics of a subset of a larger population \n",
    "- usually impossible to measure exactly\n",
    "\n",
    "**Measurement error**\n",
    "- difference between measurement & true value\n",
    "\n",
    "## Let's talk about bias\n",
    "\n",
    "The effect of sample bias is simple = our sample will be different from the population.\n",
    "\n",
    "The causes of sample bias are more complex - because there are so many!  \n",
    "\n",
    "We can eaisly demonstrate one cause of sample bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = np.random.normal(10, 3, 100000)\n",
    "\n",
    "biased = [x for x in population if x > 11]\n",
    "\n",
    "'population mean {:.2f} - biased sample mean {:.2f}'.format(np.mean(population), np.mean(biased))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if our sampling error is random, we don't see the bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for x in population:\n",
    "    if np.random.uniform() > 0.5:\n",
    "        data.append(x)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "'{:.2f}'.format(np.mean(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias is **systematic error**.\n",
    "\n",
    "One form of bias a data scientist needs to be aware of is **selection bias**.  There are many reasons why this can happen:\n",
    "- vast search = asking many different questions / training many different models\n",
    "- non-random sampling (aka sampling bias)\n",
    "- cherry picking data\n",
    "- stopping an experiment based on the result\n",
    "- after the fact selection of results\n",
    "\n",
    "Many of the mistakes above are caused directly by the data scientist :)Â \n",
    "\n",
    "A particular case of selection bias is **regression to the mean**\n",
    "- select a high performing athlete based on performance that is somewhat due to luck\n",
    "- later on the luck disapears!\n",
    "\n",
    "## Sampling error\n",
    "\n",
    "Above we talked about sampling bias - now lets talk about **sampling error**\n",
    "- sampling error\n",
    "\n",
    "We can can estimate the sampling error through simulation\n",
    "- we don't know the true statistics\n",
    "- lets instead use estimates from our small number of samples\n",
    "\n",
    "The question we are asking is\n",
    "- if the true stats were the same as the population stats\n",
    "- and we ran this experiment many times\n",
    "- how much would our estimated mean vary\n",
    "\n",
    "## Statistic sampling distributions\n",
    "\n",
    "The distribution of a statistic is known as a **sampling distribution**\n",
    "- is not the data distribution!\n",
    "\n",
    "The question we are asking is - how do statistics vary with sampling?\n",
    "- we want to know how variable our statistics are - their **sampling variability**\n",
    "\n",
    "The **sampling distribution** of a statistic shows us how a sample statistic varies\n",
    "\n",
    "## Estimating the sampling distribution using computation\n",
    "\n",
    "There is an entire literature in traditional statistics that **developed under constraints of data & computation**.  Normal approximation methods such as t-distributions rely on the Central Limit Theorem to calculate sampling distributions.\n",
    "\n",
    "We live in an era where computation is cheap - let's use it.\n",
    "\n",
    "<img src=\"assets/ram_slack.jpg\" alt=\"\" width=\"350\"/>\n",
    "\n",
    "A key tool in computational statistics is **bootstrap sampling**.\n",
    "\n",
    "## Boostrap sampling\n",
    "\n",
    "Creating new datasets by **sampling with replacement**\n",
    "- this is in contrast to shuffling / permutation sampling (without replacement)\n",
    "\n",
    "Bootstrap samples \n",
    "- are always available\n",
    "- require no assumption about the sample statistic being normally distributed\n",
    "- can be widely applied\n",
    "\n",
    "Sampling without replacement = probability of sampling a sample is unchanged\n",
    "\n",
    "The boostrap does not compensate for a small dataset\n",
    "- instead it answers questions about how additional\n",
    "\n",
    "## Standard error\n",
    "\n",
    "A metric that sums up **how variable a sampling distribution is**.  \n",
    "\n",
    "It is estimated using \n",
    "- the standard deviation of the samples\n",
    "- the sample size\n",
    "\n",
    "The standard error is\n",
    "- the expected error\n",
    "- describes variability in the estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.random.normal(10, 5, 100000)\n",
    "\n",
    "np.testing.assert_allclose(scipy_standard_error(d), np.std(d) / np.power(len(d), 0.5), rtol=1e-05)\n",
    "\n",
    "np.std(d) / np.power(len(d), 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a computational approach to estimating standard error.  Before we do this, let's introduce a new dataset.\n",
    "\n",
    "## A new dataset (no more Iris!)\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Forest+Fires\n",
    "\n",
    "Run bash commands to:\n",
    "- make a folder called `data`\n",
    "- download two text files\n",
    "- move them into `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_forest_fires()\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first look at the **data distribution** of a feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = data.plot(y='temp', kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And some of the statistics of this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, 'RH'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical\n",
    "\n",
    "Take a computational approach to estimating standard error:\n",
    "1. sample a bootstrap of n samples\n",
    "2. record the sample mean of the n samples\n",
    "3. repeat steps 1 & 2 m times - each time reporting the sample mean standard error (ie the standard deviation)\n",
    "4. produce a histogram of the sample means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence intervals\n",
    "\n",
    "A confidence interval = measurement of error in a sample estimate\n",
    "- same purpose as histograms, boxplots & standard errors\n",
    "\n",
    "The confidence interval can be thought of as\n",
    "- the interval that encloses X % of the bootstrap sampling distribution\n",
    "- an X % CI should, on average, contain similar sample estimates X % of the time\n",
    "\n",
    "The general method for generating a boostrap confidence interval:\n",
    "1. draw a bootstrap sample\n",
    "2. record the statistic (mean, var etc)\n",
    "3. repeat 1 & 2 many times\n",
    "4. trim (100-x) / 2 % from either end of the distribution - the end points are now your confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/forestfires.csv')\n",
    "col = 'temp'\n",
    "\n",
    "n_samples = 1000\n",
    "sample_size = 1000\n",
    "\n",
    "statistics = []\n",
    "for _ in range(n_samples):\n",
    "    idxs = np.random.randint(0, data.shape[0], sample_size)\n",
    "    sample_mean = np.mean(data.loc[idxs, col])\n",
    "    statistics.append(sample_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = sorted(statistics)\n",
    "\n",
    "interval = 0.95\n",
    "split = int(data.shape[0] * (1 - interval) / 2)\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = statistics[split], statistics[-split]\n",
    "\n",
    "start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.hist(statistics)\n",
    "ax.axvline(start, color='red')\n",
    "ax.axvline(end, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use a cumulative density function (CDF) to \n",
    "- visualize the distribution of sample means\n",
    "- calculate the confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x = zip(*make_cdf(statistics))\n",
    "\n",
    "y = np.array(y)\n",
    "x = np.array(x)\n",
    "\n",
    "start = x[y == 0.05]\n",
    "end = x[y == 0.95]\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.plot(x, y)\n",
    "ax.axvline(start, color='red')\n",
    "ax.axvline(end, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "[Chapter 12 of Statistics Done Wrong - Alex Reinhart](https://www.statisticsdonewrong.com/)\n",
    "\n",
    "As the sample size increases, what happens to the\n",
    "- standard error\n",
    "- standard deviation\n",
    "\n",
    "What sources of error are we not accounting for with these two statistics?\n",
    "\n",
    "Which of the three sources of error (sampling error, sampling bias or measurement) is pseudoreplication?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
