{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation\n",
    "\n",
    "## What's So Important About Backprop\n",
    "\n",
    "Backprop is a cross-disciplinary computational tool, that been discovered and rediscovered many times.\n",
    "\n",
    "From [The Master Algorithm](https://en.wikipedia.org/wiki/The_Master_Algorithm):\n",
    "\n",
    "> In fact, Rumelhart is credited with inventing backprop by the Columbus test: Columbus was not the first person to discover America, but the last.\n",
    ">\n",
    "> It turns out that Paul Werbos, a graduate student at Harvard, had proposed a similar algorithm in his PhD thesis in 1974. And in a supreme irony, Arthur Bryson and Yu-Chi Ho, two control theorists, had done the same even earlier: in 1969, the same year that Minsky and Papert published Perceptrons!\n",
    "\n",
    "\n",
    "**It speeds up training of neural networks**.  Alternatives include computing the directional derivatives via finite difference (which would mean doing millions of forward passes).\n",
    "\n",
    "## What is Backprop\n",
    "\n",
    "Backprop is a mathematical technique for quickly calculating derivatives.\n",
    "\n",
    "It's the application of *reverse-mode differentiation* (the application independent name for backprop) to neural networks.\n",
    "\n",
    "Backpropagation is not a training algorithm:\n",
    "\n",
    "- it’s an algorithm for computing the gradient,\n",
    "- gradient descent is the training algorithm.\n",
    "\n",
    "Backpropagation involves two steps:\n",
    "\n",
    "1. a forward pass from `data -> input layer -> output layer -> prediction error`,\n",
    "2. a backwards pass from `prediction error -> gradients -> output layer -> input_layer`.\n",
    "\n",
    "The error from the forward pass is backpropagated from the output layer back through the network - updating the weights in reverse order.\n",
    "\n",
    "From [The Master Algorithm](https://en.wikipedia.org/wiki/The_Master_Algorithm):\n",
    "\n",
    "> With backprop, you don’t have to figure out how to tweak each neuron’s weights from scratch, which would be too slow; you can do it layer by layer, tweaking each neuron based on how you tweaked the neurons it connects to.\n",
    "\n",
    "From [The Singularity Is Near](https://en.wikipedia.org/wiki/The_Singularity_Is_Near):\n",
    "\n",
    "> However, backpropagation is not a feasible model of training synaptic weights in an actual biological neural network, because backward connections to actually adjust the strength of the synaptic connections do not appear to exist in mammalian brains.\n",
    ">\n",
    "> In computers, however, this type of self-organizing system can solve a wide range of pattern-recognition problems, and the power of this simple model of self-organizing interconnected neurons has been demonstrated.\n",
    "\n",
    "## Gradients\n",
    "\n",
    "The gradient is both a direction and a rate of change. Both of these are valuable:\n",
    "\n",
    "- the direction can be the direction that reduces error,\n",
    "- the rate of change can be the largest (steepest) rate of change to reduce error.\n",
    "\n",
    "The change is always in the context of something else.  For neural networks, we are interested in how **error changes with respect to our parameters**.\n",
    "\n",
    "## Calculus 101\n",
    "\n",
    "Calculus is the study of change.  Below we introduce just enough calculus fundamentals to understand the chain rule and backpropagation.\n",
    "\n",
    "If I have a function:\n",
    "\n",
    "$$ f(x) = x^2 $$\n",
    "\n",
    "The algorithm to find the derivative is known as the **Power Law**:\n",
    "\n",
    "1. multiply by the power,\n",
    "2. subtract the power by one.\n",
    "\n",
    "$$ f'(x) = 2x $$\n",
    "\n",
    "$$ f(x) = 3x^4 + 2x^{2} $$\n",
    "$$ f'(x) = 12x^3 + 4x $$\n",
    "\n",
    "$$ f(x) = 8x $$\n",
    "$$ f'(x) = 8 $$\n",
    "\n",
    "If I take the derivaitve with respect to $x$ on something that doesn't depend on $x$, then the derivative is zero.  This includes:\n",
    "\n",
    "- constants $10, -1$,\n",
    "- terms that don't have an $x$ such as $y^2, \\theta$.\n",
    "\n",
    "$$ f(x) = 2x + 5y + 8 $$\n",
    "$$ f'(x) = 2 $$\n",
    "\n",
    "If I have something in brackets raised to a power, then the derivative is the power times the bracket to the power minus one, times the derivative of what is in the bracket:\n",
    "\n",
    "$$ f(x) = g(x)^3 $$\n",
    "$$ f'(x) = 3 g(x)^2 \\cdot g'(x) $$\n",
    "\n",
    "$$ f(x) = (x^2 + x)^3 $$\n",
    "$$ f' = 3(x^2 + x)^2 \\cdot (2x + 1) $$\n",
    "\n",
    "We use this rule to take the derivative of the mean square error.\n",
    "\n",
    "## Notation\n",
    "\n",
    "Calculus was discovered by multiple people around the same time - this has led to a number of competing notations:\n",
    "\n",
    "$$ \\nabla_{x} f = f' = \\frac{df}{dx} $$\n",
    "\n",
    "## Minimizing a Function\n",
    "\n",
    "Our use case of calculus is to find the minimum of a function - to find the minimum of our loss function.\n",
    "\n",
    "To find the minimum of a simple function:\n",
    "\n",
    "$$ f(x) = x^2 $$\n",
    "\n",
    "We can **sample data** from this function.  From the data below it is clear where the minimum is (but lets pretend it isn't):\n",
    "\n",
    "| x  | f(x) |\n",
    "|----|------|\n",
    "| -5 | 25   |\n",
    "| -2 | 4    |\n",
    "| 0  | 0    |\n",
    "| 2  | 4    |\n",
    "| 5  | 25   |\n",
    "\n",
    "We can take the derivative of this function, and it shows us the direction we need to take to find the minimum:\n",
    "\n",
    "$$ f'(x) = \\frac{df}{dx} = 2x $$\n",
    "\n",
    "| x  | f(x) | f'(x) |\n",
    "|----|------|-------|\n",
    "| -5 | 25   | -10   |\n",
    "| -2 | 4    | -4    |\n",
    "| 0  | 0    | 0     |\n",
    "| 2  | 4    | 4     |\n",
    "| 5  | 25   | 10    |\n",
    "\n",
    "This shows us the value of a gradient - it shows us the direction towards maximizing a function (we take the negative to minimize it).\n",
    "\n",
    "Gradient descent is an iterative process that repeatedly takes steps in the direction of the negative gradient.\n",
    "\n",
    "## Fitting a Function\n",
    "\n",
    "The example above shows how we can use gradients to find the minimum of a function.\n",
    "\n",
    "In machine learning, the function we want to minimise is an **error or loss function**.\n",
    "\n",
    "This error is the difference between two functions:\n",
    "\n",
    "- a function that we parametrize $f(x; \\theta)$ with weights $\\theta$,\n",
    "- a function that we want to learn $F(x)$.\n",
    "\n",
    "We don't have access to $F(x)$ (if we did, we wouldn't need to learn it) - what we do have access to is the ability to sample:\n",
    "\n",
    "- $x$ - features (inputs),\n",
    "- $y$ - target / label (outputs).\n",
    "\n",
    "We have three things:\n",
    "\n",
    "1. a function parametrized by weights $\\theta$\n",
    "2. samples of $x$ (features)\n",
    "3. samples $y$ (target)\n",
    "\n",
    "Lets learn from data sampled from the function:\n",
    "\n",
    "$$F(x) = 3 x^2 $$\n",
    "\n",
    "This is a parameterized function with a single feature:\n",
    "\n",
    "$$ f(x; \\theta) = \\theta x^2 $$\n",
    "\n",
    "Samples:\n",
    "\n",
    "| x  | y  |\n",
    "|----|----|\n",
    "| -1 | 3 |\n",
    "| 0  | 0  |\n",
    "| 1  | 3  |\n",
    "\n",
    "Mean square error:\n",
    "\n",
    "$$E = \\frac{1}{2} (f(x; \\theta) - y)^2 = \\frac{1}{2} (\\theta x^2  - y)^2 $$\n",
    "\n",
    "Derivative of the error:\n",
    "\n",
    "$$E' = \\frac{dE}{d\\theta} = 2(\\theta x^2 - y) \\cdot x^2 $$\n",
    "\n",
    "We can now perform an iterative process to update our parameter $\\theta$, starting from an initial $\\theta = 0 $:\n",
    "\n",
    "| x  | y  | E' |\n",
    "|----|----|----|\n",
    "| -1 | 3 |  -6 |\n",
    "| 0  | 0  | 0  |\n",
    "| 1  | 3  | -6 |\n",
    "\n",
    "How do we update our parameter? One way is to average over the three samples:\n",
    "\n",
    "$$E' = (-6 + 0 -6) / 3 = -4.0$$\n",
    "\n",
    "As we are minimizing the error, we take the negative of the gradient and use it to update our parameter:\n",
    "\n",
    "$$\\theta_{1} = \\theta_{0} + E' = 0 + 4 = 4.0 $$\n",
    "\n",
    "Which is not so far away from the true value of $3$.\n",
    "\n",
    "Here we are seeing the need for two of the most important hyperparameters in training neural networks - the **learning rate** & **batch size**. Can you see how they would fit into our example?\n",
    "\n",
    "## Practical\n",
    "\n",
    "Do this (on paper!) for $f(x) = 5 x^3$\n",
    "\n",
    "## Partial Derivatives\n",
    "\n",
    "In the example above we used our prior knowledge of the true function $F(x)$ to engineer a single feature $x^2$.\n",
    "\n",
    "What happens if we don't encode this knowledge, and instead have multiple parameters?\n",
    "\n",
    "$$ f(x;\\theta) = \\theta_{0} x^2 + \\theta_{1} x + \\theta_{2} $$\n",
    "\n",
    "We now need partial derivatives:\n",
    "\n",
    "$$ \\frac{\\partial f}{\\partial \\theta_{0}} = x^2 $$\n",
    "\n",
    "$$ \\frac{\\partial f}{\\partial \\theta_{1}} = x $$\n",
    "\n",
    "$$ \\frac{\\partial f}{\\partial \\theta_{2}} = 1 $$\n",
    "\n",
    "## Practical\n",
    "\n",
    "Lets pick some initial parameters (this is **weight initialization**):\n",
    "\n",
    "$$\\theta = [1,1,1]$$\n",
    "\n",
    "Calculate the partial derivatives and update the parameters using the following data:\n",
    "\n",
    "| x  | y  |\n",
    "|----|----|\n",
    "| -2 | -5 |\n",
    "| 0  | 1  |\n",
    "| 1  | 4  |\n",
    "\n",
    "## The Linear Perceptron\n",
    "\n",
    "If we have a feature of length 3:\n",
    "\n",
    "$$x = [x_{0}, x_{1}, x_{2}]$$\n",
    "\n",
    "Let give each feature its own parameter:\n",
    "\n",
    "$$ \\theta = [\\theta_{0}, \\theta_{1}, \\theta_{2}] $$\n",
    "\n",
    "And combine them together using a linear combination:\n",
    "\n",
    "$$ f(x; \\theta) = x_{0} \\cdot \\theta_{0} + x_{1} \\cdot \\theta_{1} + x_{2} \\cdot \\theta_{2} $$\n",
    "\n",
    "$$ f(x; \\theta) = \\sum x \\cdot \\theta $$\n",
    "\n",
    "## The Perceptron\n",
    "\n",
    "From [The Singularity Is Near](https://en.wikipedia.org/wiki/The_Singularity_Is_Near):\n",
    "\n",
    "> This basic neural-net model has a neural “weight” (representing the “strength” of the connection) for each synapse and a nonlinearity (firing threshold) in the neuron soma (cell body).\n",
    "\n",
    "This linear combination won't be much use for learning a non-linear function.  Let's adjust notation in anticipation of complexity:\n",
    "\n",
    "$$ z(x) = \\sum x \\theta $$\n",
    "\n",
    "Lets add an activation function after the linear combination - lets use a sigmoid (which is a special case of the logistic function):\n",
    "\n",
    "$$ a(z) = \\frac{1}{1 + e^{-z}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Single Hidden Layer Neural Network\n",
    "\n",
    "Three layers in total - input, hidden & output.\n",
    "\n",
    "Parameters from input -> hidden layer:\n",
    "\n",
    "$$w_{0}, b_{0}$$\n",
    "\n",
    "Linear combination of parameters:\n",
    "\n",
    "$$z_{0} = \\sum X \\cdot w_{0} + b_{0}$$\n",
    "\n",
    "Hidden layer activation function (sigmoid):\n",
    "\n",
    "$$a_{0} = \\frac{1}{1 + \\exp^{-z}} $$\n",
    "\n",
    "Output layer linear combination:\n",
    "\n",
    "$$z_{1} = \\sum a_{0} \\cdot w_{1} + b_{1}$$\n",
    "\n",
    "Error function:\n",
    "\n",
    "$$E = \\frac{1}{2} (z_{1} - y)^2$$\n",
    "\n",
    "## Partial Derivatives of These Components\n",
    "\n",
    "Partial derivative of the linear combination of the input layer with respect to a weight or bias in that layer:\n",
    "\n",
    "$$ \\frac{\\partial z_{0}}{\\partial  w_{0}} = X $$\n",
    "\n",
    "$$ \\frac{\\partial z_{0}}{\\partial  b_{0}} = 1 $$\n",
    "\n",
    "Partial derivative of the sigmoid activation on the hidden layer with respect to the linear combination:\n",
    "\n",
    "$$ \\frac{\\partial a_{0}}{\\partial  z_{0}} = a_{0}(z_{0}) * (1-a_{0}(z_{0})) $$\n",
    "\n",
    "Partial derivative of the output layer linear combination with respect to the activation:\n",
    "\n",
    "$$ \\frac{\\partial z_{1}}{\\partial a_{0}} = w_{1} $$\n",
    "\n",
    "Partial derivative of the error with respect to the output layer:\n",
    "\n",
    "$$ \\frac{\\partial E}{\\partial z_{1}} = z_{1} - y $$\n",
    "\n",
    "Our full model can now be written as a composition of functions:\n",
    "\n",
    "$$ f(x; \\theta) = z_{1}(a_{0}(z_{0}(x))) $$\n",
    "\n",
    "We want change each of our parameters with respect to minimize the error:\n",
    "\n",
    "$$ \\frac{\\partial E}{\\partial w_{0}}, \\frac{\\partial E}{\\partial b_{0}}, \\frac{\\partial E}{\\partial w_{1}}, \\frac{\\partial E}{\\partial b_{1}} $$\n",
    "\n",
    "## The Chain Rule\n",
    "\n",
    "When we have compositions of functions:\n",
    "\n",
    "$$ f(x) = a(z(x)) $$\n",
    "\n",
    "The **chain rule** shows us how gradients flow through these compositions of functions:\n",
    "\n",
    "$$ \\frac{df}{dz} = \\frac{df}{da} \\cdot \\frac{da}{dz} $$\n",
    "\n",
    "## Practical\n",
    "\n",
    "You now have all the tools to derive update equations for all our weights and biases - do so on paper."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
