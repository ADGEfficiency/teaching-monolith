{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `multiprocessing`\n",
    "\n",
    "Parallel computation on a single machine in Python\n",
    "- one of my most important tools\n",
    "- Python standard library\n",
    "\n",
    "\n",
    "## Python standard library parallel computation ecosystem\n",
    "\n",
    "[Multiprocessing Vs. Threading In Python - Sid Panjwani](https://timber.io/blog/multiprocessing-vs-multithreading-in-python-what-you-need-to-know/)\n",
    "\n",
    "`threading` - uses threads (same memory space)\n",
    "- helps with network issues\n",
    "\n",
    "`multiprocessing` - uses processes (different memory space)\n",
    "- help with compute issues\n",
    "\n",
    "How does this relate to CPU cores\n",
    "- CPU cores are fixed (usually 4-16 in laptops - depends on your physical hardware)\n",
    "- more cores = true parallelism (opposed to the very fast task switching done by the OS\n",
    "- your computer can have many threads and many processes (depends on the OS)\n",
    "- the OS will schedule these threads/processes to available cores\n",
    "- a single thread consumes an entire core\n",
    "\n",
    "[Multithreading and multicore differences](https://stackoverflow.com/questions/11835046/multithreading-and-multicore-differences)\n",
    "\n",
    "*But my CPU core has two threads*\n",
    "- this is a different use of the term (the hardware thread)\n",
    "- CPU having threads allows a core to run thread in parallel, as if there were multiple cores\n",
    "- known as hyperthreading\n",
    "\n",
    "\n",
    "## Why do we need `multiprocessing`?\n",
    "\n",
    "Python has a Global Interpreter Lock (GIL) that prevents parallelizing computation across multiple cores\n",
    "- Python is not thread safe\n",
    "- requires a lock when accessing an object (a form of memory management)\n",
    "\n",
    "\n",
    "## What can be hard in multiprocessing?\n",
    "\n",
    "Sharing things between processes\n",
    "- solution = don't use it in this way\n",
    "- make every process independent\n",
    "- a functional style = no interaction (because interaction = side effects!)\n",
    "\n",
    "\n",
    "## `multiprocessing` 101\n",
    "\n",
    "We map functions to data\n",
    "- but in parallel!\n",
    "\n",
    "First let's do a simple `map` in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1110239028930664\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def subtract(x, sleep=0.01):\n",
    "    time.sleep(sleep)\n",
    "    return x*x\n",
    "\n",
    "data = np.random.uniform(0, 100, size=100).tolist()\n",
    "st = time.time()\n",
    "result = list(map(subtract, data))\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's parallelize this using `multiprocessing`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2782878875732422\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "num_process = 8\n",
    "st = time.time()\n",
    "with Pool(num_process) as pool:\n",
    "    out = pool.map(subtract, data)\n",
    "    \n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common use case is to have arguments for the function being mapped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1649940013885498\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "st = time.time()\n",
    "with Pool(num_process) as p:\n",
    "    rewards = p.map(partial(subtract, sleep=0.0), data)\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when we remove our sleep, the non-mulitprocessing `map` is faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004360675811767578\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "result = list(map(partial(subtract, sleep=0.0), data))\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed computation has overhead (fixed + variable) \n",
    "- make sure your function runs long enough to justify it\n",
    "\n",
    "## Exercise - bitcoin mining\n",
    "\n",
    "Write multiprocessed code to solve a hashing problem (similar to how *proof of work* works in Bitcoin)\n",
    "- take a given input string (base string)\n",
    "- add strings on the end of it until you get a hash with a leading `0`\n",
    "\n",
    "We can use the `hash` Python builtin to hash a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7556065562850184147"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash('I miss DSR already')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add characters onto the end of this string and we will get a different hash:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "579494584986873439"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash('I miss DSR already!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few ways to solve this - one is to write a function that:\n",
    "- randomly selects n characters\n",
    "- adds those characters onto the string\n",
    "- if the hash starts with 0, return the characters & a success code\n",
    "- otherwise return the characters and a failure code\n",
    "\n",
    "This function can be run in parallel :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_string = 'I miss DSR already'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
