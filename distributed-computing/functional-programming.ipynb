{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Programming \n",
    "\n",
    "Functional programming in Python - things we will cover:\n",
    "\n",
    "- map,\n",
    "- lazy computation,\n",
    "- lambda functions,\n",
    "- filter,\n",
    "- reduce.\n",
    "\n",
    "Three attributes of functional programs:\n",
    "\n",
    "1. no side effects,\n",
    "2. variables don't vary - immutable data,\n",
    "3. first class functions - no objects and no state.\n",
    "\n",
    "\n",
    "## Resources\n",
    "\n",
    "[Functional Programming in Python\n",
    "By Marcus Sanatan](https://stackabuse.com/functional-programming-in-python/)\n",
    "\n",
    "[Clean Architecture - Uncle Bob Martin](https://www.amazon.co.uk/Clean-Architecture-Craftsmans-Software-Structure/dp/0134494164)\n",
    "\n",
    "[What is Functional Programming? - Scott Murphy](https://www.youtube.com/watch?v=KHojnWHemO0)\n",
    "\n",
    "## What is functional programming?\n",
    "\n",
    "Three things:\n",
    "\n",
    "1. no side effects,\n",
    "2. variables don't vary / immutable data,\n",
    "3. first class functions - no objects and no state,\n",
    "\n",
    "Examples of functional programming languages include Lisp, Haskell, Erlang, Clojure.\n",
    "\n",
    "Also a useful idea when thinking about implementations\n",
    "\n",
    "[John Carmack (on Parallel Implementations)](http://sevangelatos.com/john-carmack-on-parallel-implementations/) - it is eaiser to switch out implementations if ideas are expressed as pure functions.  Internal state & multiple entry points make programming harder.\n",
    "\n",
    "## 1. No side effects\n",
    "\n",
    "- same inputs -> same outputs - always,\n",
    "- idempotent - things always run / perform the same way,\n",
    "- no dependency on the state of the outside world.\n",
    "\n",
    "Not doing something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(data):\n",
    "    new_data = clean(data)\n",
    "    database.save(new_data)\n",
    "    database.load(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Variables that don't vary - immutable data\n",
    "\n",
    "Variables are only ever initialized:\n",
    "\n",
    "- they are never changed,\n",
    "- this avoids problems such as race conditions / deadlocks.\n",
    "\n",
    "Variables being immutable means we can't do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  can't do this - mutates the object in place\n",
    "def f(x):\n",
    "    x += 1\n",
    "    return x\n",
    "\n",
    "#  can do this - creates a new object\n",
    "def f(x):\n",
    "    x = x + 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of immutable data is the reading & writing of the input & output of each stage in a data pipeline to storage (commonly S3).\n",
    "\n",
    "## 3. Functions are first class\n",
    "\n",
    "We can pass functions around like other variables (also known as higher order functions).\n",
    "\n",
    "Below we pass the `sum` function into a generic `controller` function - which just executes the function it is given:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def controller(func, data):\n",
    "    return func(data)\n",
    "\n",
    "data = [1, 2, 3]\n",
    "controller(sum, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing in another function (`len`) gives different results - the length of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller(len, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map\n",
    "\n",
    "Apply a function to each element of an iterable - similar to `df.apply` in pandas and to a `for` loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower(s):\n",
    "    return s.lower()\n",
    "\n",
    "cities = ['Berlin', 'Auckland', 'London', 'Sheffield']\n",
    "m = map(lower, cities)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python returns a map object (technically a generator?), not the transformed data.  This is an example of **lazy computation**, which is a two step process:\n",
    "\n",
    "1. build a pipeline/graph\n",
    "2. put data through it when needed\n",
    "\n",
    "Examples include Tensorflow 1, Spark, Python generators, Prefect flows.\n",
    "\n",
    "As we are more impatient than lazy, we can get all the processed data by calling `list` on the generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(lower, cities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda functions\n",
    "\n",
    "Lambda functions are anonymous - meaning the function is not assigned to a variable. \n",
    "\n",
    "In Python we can have objects with no variable reference (until they get garbage collected :)\n",
    "\n",
    "We can do our same `.lower` map using an anonymous lambda function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(lambda x: x.lower(), cities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the object above we define a lambda function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda x: x.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do more complex things in lambdas, such as accessing elements of the input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "populations = [\n",
    "    ('Berlin', 3.7, 'eu'),\n",
    "    ('Auckland', 1.7, 'pac'),\n",
    "    ('London', 8.9, 'eu'),\n",
    "    ('Sheffield', 0.5, 'eu')\n",
    "]\n",
    "\n",
    "list(map(lambda x: (x[0], x[1] * 1000), populations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have total flexibility in **what data structure** we use in the iterable, and **how we interact with it** in the lambda.  We have decomposed and separated the data from the behaviour!\n",
    "\n",
    "We could map over a sequence of namedtuples, and access elements using the attribute `.` syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "pop = namedtuple('city', ['city', 'population', 'continent'])\n",
    "\n",
    "populations = [pop(*p) for p in populations]\n",
    "\n",
    "list(map(lambda x: (x.city, x.population * 1000), populations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce\n",
    "\n",
    "Reduce will aggregate a sequence to single values (either a single value for the entire sequence, or one single value per group).  Also known as aggregation or a groupby.\n",
    "\n",
    "The Python standard library has it's own reduce function - inconveniently (and unlike `map` or `sum`) it is not a builtin  - it is hidden away in `functools.reduce`.  This object operates on each element and accumulates, returning a single aggregated example.\n",
    "\n",
    "We can use this `reduce` function on our `populations` dataset:\n",
    "\n",
    "- define a lambda function that adds on the population of the sequence to the total,\n",
    "- our sequence populations,\n",
    "- an initial value of `0`.\n",
    "\n",
    "We can first map this out in normal Python - iterating over a list and incrementing a float:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for p in populations:\n",
    "    total += p.population\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equivilant of the above using `functools.reduce` is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "reduce(lambda total, pop: total + pop[1], populations, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use this `reduce` function to groupby continent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb(acc, city):\n",
    "    acc[city.continent].append(city.city)\n",
    "    return acc\n",
    "\n",
    "reduce(\n",
    "    gb,\n",
    "    populations,\n",
    "    {'eu': [], 'pac': []}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter\n",
    "\n",
    "Tests each element, keeps those that pass - similar to boolean masking in pandas/numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(filter(lambda x: x[1] > 1.0, populations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical\n",
    "\n",
    "Create a data processing pipeline that selects the cities that have populations greater than the average of all cities.\n",
    "\n",
    "Two steps:\n",
    "1. `reduce` to find the average of all cities,\n",
    "2. `filter` to select using cities above that average.\n",
    "\n",
    "This can be done in a single reduce step - suggest first getting the two step solution working :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical\n",
    "\n",
    "Implement the same pipeline using two list comprehensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "In Python, any combination of `map` & `filter` can be done with a single list comprehension - why do we need to use two in the example above?\n",
    "\n",
    "## Practical\n",
    "\n",
    "Create a data processing pipeline that finds the average population for both continents:\n",
    "1. reduce to (key, (populations)),\n",
    "2. map from (key, (populations)) to (key, avg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
