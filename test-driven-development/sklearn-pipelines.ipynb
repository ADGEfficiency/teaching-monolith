{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Classes 101\n",
    "\n",
    "Before we introduce sklearn piplines, a bit of background about classes & inheritance in Python\n",
    "\n",
    "Lets imagine we want to build three agents that take actions (either always turn left, always turn right or randomly do either)\n",
    "\n",
    "We can do this without inheritance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "\n",
    "class Left:\n",
    "    def __init__(self):\n",
    "        self.name = 'left'\n",
    "        self.age = 0\n",
    "        \n",
    "    def act(self):\n",
    "        self.age += 1\n",
    "        return 'go left'\n",
    "    \n",
    "\n",
    "class Right:\n",
    "    def __init__(self):\n",
    "        self.name = 'right'\n",
    "        self.age = 0\n",
    "        \n",
    "    def act(self):\n",
    "        self.age += 1\n",
    "        return 'go right'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can instantiate these classes, and access their methods and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'left'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left = Left()\n",
    "\n",
    "left.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go right', 'go right', 'go right']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right = Right()\n",
    "\n",
    "acts = [right.act() for _ in range(3)]\n",
    "acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right.age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see there is a lot of repeated code in the examples above - lets see how inheritance might help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.age = 0\n",
    "        \n",
    "    def act(self):\n",
    "        self.age += 1\n",
    "        \n",
    "        \n",
    "class Left(Agent):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "        \n",
    "    def act(self):\n",
    "        super().act()\n",
    "        return 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['left', 'left', 'left', 'left']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left = Left('child left')\n",
    "\n",
    "acts = [left.act() for _ in range(4)]\n",
    "acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left.age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['right', 'right', 'right', 'right', 'right']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Right(Agent):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "        \n",
    "    def act(self):\n",
    "        super().act()\n",
    "        return 'right'\n",
    "\n",
    "right = Right('child right')\n",
    "acts = [right.act() for _ in range(5)]\n",
    "acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right.age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'child right'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how\n",
    "- data can flow from the child class to the parent via super\n",
    "- we can access the methods of the parent on the child\n",
    "- we define the common functionality once\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn pipelines\n",
    "\n",
    "Why pipelines?\n",
    "- reusable\n",
    "- readable\n",
    "- testable\n",
    "\n",
    "There are two kinds of pipeline objects\n",
    "- transformers (i.e. normalizing or standardizing)\n",
    "- estimators (i.e. fitting a model)\n",
    "\n",
    "The focus on this class is on transformers - but the real power of a pipeline comes when you have an estimator on the end\n",
    "\n",
    "Lets first take a look at a transformer that adds a number to each row of a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "\n",
    "class Adder(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, num):\n",
    "        self.num = num\n",
    "\n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        return x + np.full(shape=x.shape, fill_value=self.num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are 2 methods:\n",
    "\n",
    "1. fit - learns information about the data (and becomes a stateful transformer)\n",
    "2. transform - applies the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Adder(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 2.],\n",
       "       [2., 2.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.fit_transform(np.zeros((2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical\n",
    "\n",
    "Build two tested transformers (write the tests first!)\n",
    "1. select a column\n",
    "2. standardization\n",
    "\n",
    "By standardization I mean\n",
    "\n",
    "$$ y = \\frac{x-\\mu}{\\sigma} $$ \n",
    "\n",
    "Then write an integration test that tests a pipeline of the two transformers together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a pipeline\n",
    "\n",
    "A pipline should end with an estimator - essentially a stateful transformer that learns statistics from data.  Often the last step will be a model.\n",
    "\n",
    "Here we will break with the TDD style and bulid the pipeline first (don't worry - you will get the chance to test it later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_column_selector():\n",
    "    names = ['a', 'b', 'j']\n",
    "    \n",
    "    data = np.hstack([np.arange(3), np.arange(3) * 10, np.arange(3) * 100]).reshape(-1, 3)\n",
    "    \n",
    "    selector = ColumnSelector(names, ['a'])\n",
    "    np.testing.assert_array_equal(\n",
    "        selector.transform(data), np.zeros(3).reshape(3, 1)\n",
    "    )\n",
    "    selector = ColumnSelector(names, ['j'])\n",
    "    np.testing.assert_array_equal(\n",
    "        selector.transform(data), np.array([2, 20, 200]).reshape(3, 1)\n",
    "    )\n",
    "    selector = ColumnSelector(names, ['a', 'j'])\n",
    "    np.testing.assert_array_equal(\n",
    "        selector.transform(data), np.array([[0, 2], [0, 20], [0, 200]])\n",
    "    )\n",
    "\n",
    "    \n",
    "class ColumnSelector(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, feature_names, selected_names):\n",
    "        self.feature_names = feature_names\n",
    "        self.selected_names = selected_names\n",
    "\n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        idxs = [\n",
    "            self.feature_names.index(n) \n",
    "            for n in self.selected_names\n",
    "        ]\n",
    "        return x[:, idxs]\n",
    "    \n",
    "test_column_selector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_standardizer():\n",
    "    data = np.random.uniform(size=20).reshape((10, 2)) * 100\n",
    "    standardizer = Standardizer()\n",
    "    standardized = standardizer.fit_transform(data)\n",
    "    np.testing.assert_array_less(np.mean(standardized, axis=0), 1e-14)\n",
    "    np.testing.assert_allclose(np.var(standardized, axis=0), 1)\n",
    "\n",
    "    \n",
    "class Standardizer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, x, y = None):\n",
    "        self.means = np.mean(x, axis=0, keepdims=True)\n",
    "        self.stds = np.std(x, axis=0, keepdims=True)\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        return (x - self.means) / self.stds\n",
    "    \n",
    "test_standardizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columnselector',\n",
       "                 ColumnSelector(feature_names=['a', 'b', 'c'],\n",
       "                                selected_names=['a', 'c'])),\n",
       "                ('standardizer', Standardizer())],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe = make_pipeline(ColumnSelector(['a', 'b', 'c'], ['a', 'c']), Standardizer())\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.random.uniform(size=15).reshape((5, 3)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7906889 , -1.80155413],\n",
       "       [ 0.09156311,  0.28370057],\n",
       "       [-0.60781632,  0.05496521],\n",
       "       [-1.54422337,  1.27956567],\n",
       "       [ 1.26978768,  0.18332267]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_train = pipe.fit_transform(train)\n",
    "processed_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply the same transformation to another dataset (i.e. the test set) by calling the `transform` method.  \n",
    "\n",
    "This is a common misunderstanding in machine learning - you shouldn't refit any preprocessing statistics when testing (in the same way that you don't refit your model parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.52377907, -0.51514797],\n",
       "       [ 2.45170606, -0.53616539]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.random.uniform(size=6).reshape((2, 3)) * 100\n",
    "\n",
    "processed_test = pipe.transform(test)\n",
    "processed_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical\n",
    "\n",
    "Write an integration test of the entire pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pipe():\n",
    "    \n",
    "    pipe = make_pipeline(ColumnSelector(['a', 'b', 'c'], ['a', 'c']), Standardizer())\n",
    "\n",
    "    data = np.random.uniform(size=15).reshape((5, 3)) * 100\n",
    "    \n",
    "    res = pip.fit_transform(data)\n",
    "    \n",
    "    test = pip.transform(data_other_data)\n",
    "    \n",
    "    test.mean != 0\n",
    "    \n",
    "    assert res == expected\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
